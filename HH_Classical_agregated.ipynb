{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HH_Classical_agregated.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_NNsRygHox4",
        "colab_type": "text"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYI2r7qqHpBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zF7nu3fHqcO",
        "colab_type": "code",
        "outputId": "092aa88b-421a-4f70-ae88-bffd640fbfea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP3M_7jXHrf4",
        "colab_type": "code",
        "outputId": "14c9e642-7829-475a-c787-fbe78a1178fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as mn\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "import plotly\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as mn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "\n",
        "import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import SimpleRNN\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "from copy import copy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u40t1z7nVTfo",
        "colab_type": "code",
        "outputId": "69abbbdf-1af4-48c0-f7ca-0347e84cfaad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        }
      },
      "source": [
        "!ls drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Colab Notebooks'\t     MatlabResults\n",
            " Figures\t\t     Models\n",
            " HH_ag.csv\t\t     para_comb_20p_sample.csv\n",
            " HH_paramter_space_40s.csv   PR_ag.csv\n",
            " HH_voltage_40s.csv\t     voltages_AP_30sek_sample.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrGn27ylVguu",
        "colab_type": "code",
        "outputId": "7fa540cd-1dc6-4c84-e661-a142ceca3879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "%%time\n",
        "HHss_df = pd.read_csv(\"drive/My Drive/HH_paramter_space_40s.csv\",index_col=0)\n",
        "names = ['gbar_Na','gbar_L','E_L','Cm','gbar_K','E_Na','E_K']\n",
        "HHss_df.columns = names\n",
        "names = HHss_df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 21.2 ms, sys: 7.7 ms, total: 28.9 ms\n",
            "Wall time: 42.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ngKV_CXV3oN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HHag_df = pd.read_csv(\"drive/My Drive/HH_ag.csv\",index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3Ul3R1BWC5h",
        "colab_type": "code",
        "outputId": "2ada14f7-b221-4198-e01c-300e866a42fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "HHag_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_ap</th>\n",
              "      <th>first_ap_time</th>\n",
              "      <th>first_ap_amp</th>\n",
              "      <th>first_ap_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>26</td>\n",
              "      <td>42.682561</td>\n",
              "      <td>63.846107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>52.059134</td>\n",
              "      <td>54.095856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>42.537257</td>\n",
              "      <td>59.980696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>56.381921</td>\n",
              "      <td>53.296342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>37.084930</td>\n",
              "      <td>61.620318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   n_ap  first_ap_time  first_ap_amp  first_ap_width\n",
              "0     5             26     42.682561       63.846107\n",
              "1     1             27     52.059134       54.095856\n",
              "2     1             22     42.537257       59.980696\n",
              "3     1             23     56.381921       53.296342\n",
              "4     2             26     37.084930       61.620318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waqQrUabH__E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HHn_ap_df = HHag_df['n_ap']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VxZmYQUIGbK",
        "colab_type": "code",
        "outputId": "ef16fec2-f82f-473c-8260-f3fa6e591ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "HHag_df = HHag_df[['first_ap_time','first_ap_amp','first_ap_width']]\n",
        "print(HHag_df.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2187, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6F0mwXkIglh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ag_indexes = ~pd.isna(HHag_df).any(axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeheIUByIh23",
        "colab_type": "code",
        "outputId": "0010f5bc-417c-4d6d-a6ab-9c1c4e612181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "HHss_ag_df = HHss_df[ag_indexes]\n",
        "HHag_df = HHag_df[ag_indexes]\n",
        "print(HHss_ag_df.shape)\n",
        "print(HHag_df.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2187, 7)\n",
            "(2187, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzZQrfCYKE9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HHss_ag = HHss_ag_df.values\n",
        "HHag = HHag_df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF5JRFNoJstH",
        "colab_type": "text"
      },
      "source": [
        "# Standardize and scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hCO4gPNJaKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Train, X_test, y_Train, y_test = train_test_split(HHss_ag,HHag,test_size=0.3,random_state=111)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6DVWgqpJtM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scx = StandardScaler()\n",
        "scy = StandardScaler()\n",
        "\n",
        "\n",
        "X_Train = scx.fit_transform(X_Train)\n",
        "y_Train = scy.fit_transform(y_Train)\n",
        "\n",
        "X_test = scx.transform(X_test)\n",
        "y_test = scy.transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ceoMqE-Ju5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_Train,y_Train,test_size=0.2,random_state=1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8Xd_5xrKfuC",
        "colab_type": "text"
      },
      "source": [
        "## Models train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXBINy1NLcLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def r_square(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st4vpavLKgyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model1 = models.Sequential()\n",
        "model1.add(layers.Dense(9, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model1.add(layers.Dense(y_train.shape[1]))\n",
        "model1.compile(optimizer='adam', loss='mse', metrics=[r_square])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfeAn4CAOjW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils.vis_utils import plot_model\n",
        "#plot_model(model1, to_file=\"drive/My Drive/Figures/models/HH_ag_arch.png\", show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwgEfao7Kj2C",
        "colab_type": "code",
        "outputId": "7fe52e25-c126-44a1-c963-822024f14c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58616
        }
      },
      "source": [
        "%%time\n",
        "history1 = model1.fit(X_Train, y_Train,\n",
        "                  epochs=2000,\n",
        "                  batch_size=256,\n",
        "                  verbose=0,\n",
        "                  validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1530 samples, validate on 306 samples\n",
            "Epoch 1/2000\n",
            "1530/1530 [==============================] - 0s 299us/step - loss: 1.7025 - r_square: -0.7074 - val_loss: 1.6211 - val_r_square: -0.5972\n",
            "Epoch 2/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 1.5639 - r_square: -0.5663 - val_loss: 1.4950 - val_r_square: -0.4726\n",
            "Epoch 3/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 1.4433 - r_square: -0.4454 - val_loss: 1.3853 - val_r_square: -0.3642\n",
            "Epoch 4/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 1.3351 - r_square: -0.3404 - val_loss: 1.2913 - val_r_square: -0.2714\n",
            "Epoch 5/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 1.2462 - r_square: -0.2470 - val_loss: 1.2098 - val_r_square: -0.1909\n",
            "Epoch 6/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 1.1671 - r_square: -0.1674 - val_loss: 1.1397 - val_r_square: -0.1218\n",
            "Epoch 7/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 1.0999 - r_square: -0.1006 - val_loss: 1.0793 - val_r_square: -0.0621\n",
            "Epoch 8/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 1.0425 - r_square: -0.0434 - val_loss: 1.0266 - val_r_square: -0.0102\n",
            "Epoch 9/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.9928 - r_square: 0.0062 - val_loss: 0.9806 - val_r_square: 0.0353\n",
            "Epoch 10/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.9481 - r_square: 0.0512 - val_loss: 0.9403 - val_r_square: 0.0751\n",
            "Epoch 11/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.9091 - r_square: 0.0902 - val_loss: 0.9044 - val_r_square: 0.1104\n",
            "Epoch 12/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.8752 - r_square: 0.1248 - val_loss: 0.8719 - val_r_square: 0.1425\n",
            "Epoch 13/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.8441 - r_square: 0.1559 - val_loss: 0.8424 - val_r_square: 0.1716\n",
            "Epoch 14/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.8161 - r_square: 0.1838 - val_loss: 0.8152 - val_r_square: 0.1983\n",
            "Epoch 15/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.7898 - r_square: 0.2094 - val_loss: 0.7901 - val_r_square: 0.2231\n",
            "Epoch 16/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.7658 - r_square: 0.2329 - val_loss: 0.7664 - val_r_square: 0.2464\n",
            "Epoch 17/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.7431 - r_square: 0.2558 - val_loss: 0.7440 - val_r_square: 0.2684\n",
            "Epoch 18/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.7217 - r_square: 0.2778 - val_loss: 0.7226 - val_r_square: 0.2895\n",
            "Epoch 19/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.7016 - r_square: 0.2985 - val_loss: 0.7021 - val_r_square: 0.3097\n",
            "Epoch 20/2000\n",
            "1530/1530 [==============================] - 0s 20us/step - loss: 0.6821 - r_square: 0.3181 - val_loss: 0.6823 - val_r_square: 0.3291\n",
            "Epoch 21/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.6630 - r_square: 0.3365 - val_loss: 0.6632 - val_r_square: 0.3479\n",
            "Epoch 22/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.6451 - r_square: 0.3546 - val_loss: 0.6447 - val_r_square: 0.3661\n",
            "Epoch 23/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.6271 - r_square: 0.3722 - val_loss: 0.6266 - val_r_square: 0.3838\n",
            "Epoch 24/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.6101 - r_square: 0.3900 - val_loss: 0.6088 - val_r_square: 0.4014\n",
            "Epoch 25/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.5930 - r_square: 0.4067 - val_loss: 0.5913 - val_r_square: 0.4185\n",
            "Epoch 26/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.5765 - r_square: 0.4232 - val_loss: 0.5740 - val_r_square: 0.4355\n",
            "Epoch 27/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.5599 - r_square: 0.4399 - val_loss: 0.5569 - val_r_square: 0.4523\n",
            "Epoch 28/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.5439 - r_square: 0.4555 - val_loss: 0.5398 - val_r_square: 0.4691\n",
            "Epoch 29/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.5276 - r_square: 0.4723 - val_loss: 0.5229 - val_r_square: 0.4857\n",
            "Epoch 30/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.5115 - r_square: 0.4886 - val_loss: 0.5061 - val_r_square: 0.5022\n",
            "Epoch 31/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.4957 - r_square: 0.5042 - val_loss: 0.4893 - val_r_square: 0.5187\n",
            "Epoch 32/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.4794 - r_square: 0.5204 - val_loss: 0.4727 - val_r_square: 0.5350\n",
            "Epoch 33/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.4635 - r_square: 0.5366 - val_loss: 0.4559 - val_r_square: 0.5515\n",
            "Epoch 34/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.4476 - r_square: 0.5522 - val_loss: 0.4391 - val_r_square: 0.5681\n",
            "Epoch 35/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.4316 - r_square: 0.5684 - val_loss: 0.4223 - val_r_square: 0.5846\n",
            "Epoch 36/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.4154 - r_square: 0.5841 - val_loss: 0.4055 - val_r_square: 0.6011\n",
            "Epoch 37/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.3994 - r_square: 0.6004 - val_loss: 0.3887 - val_r_square: 0.6176\n",
            "Epoch 38/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.3834 - r_square: 0.6166 - val_loss: 0.3718 - val_r_square: 0.6342\n",
            "Epoch 39/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.3674 - r_square: 0.6323 - val_loss: 0.3554 - val_r_square: 0.6503\n",
            "Epoch 40/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.3514 - r_square: 0.6483 - val_loss: 0.3393 - val_r_square: 0.6661\n",
            "Epoch 41/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.3360 - r_square: 0.6638 - val_loss: 0.3238 - val_r_square: 0.6814\n",
            "Epoch 42/2000\n",
            "1530/1530 [==============================] - 0s 20us/step - loss: 0.3212 - r_square: 0.6790 - val_loss: 0.3083 - val_r_square: 0.6966\n",
            "Epoch 43/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.3062 - r_square: 0.6937 - val_loss: 0.2935 - val_r_square: 0.7112\n",
            "Epoch 44/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.2917 - r_square: 0.7080 - val_loss: 0.2791 - val_r_square: 0.7253\n",
            "Epoch 45/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.2778 - r_square: 0.7222 - val_loss: 0.2654 - val_r_square: 0.7388\n",
            "Epoch 46/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.2644 - r_square: 0.7352 - val_loss: 0.2523 - val_r_square: 0.7516\n",
            "Epoch 47/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.2519 - r_square: 0.7479 - val_loss: 0.2399 - val_r_square: 0.7638\n",
            "Epoch 48/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.2397 - r_square: 0.7606 - val_loss: 0.2282 - val_r_square: 0.7753\n",
            "Epoch 49/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.2280 - r_square: 0.7718 - val_loss: 0.2173 - val_r_square: 0.7861\n",
            "Epoch 50/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.2175 - r_square: 0.7821 - val_loss: 0.2071 - val_r_square: 0.7961\n",
            "Epoch 51/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.2074 - r_square: 0.7924 - val_loss: 0.1977 - val_r_square: 0.8053\n",
            "Epoch 52/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.1982 - r_square: 0.8017 - val_loss: 0.1890 - val_r_square: 0.8138\n",
            "Epoch 53/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.1896 - r_square: 0.8101 - val_loss: 0.1812 - val_r_square: 0.8216\n",
            "Epoch 54/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.1817 - r_square: 0.8179 - val_loss: 0.1742 - val_r_square: 0.8284\n",
            "Epoch 55/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.1750 - r_square: 0.8245 - val_loss: 0.1678 - val_r_square: 0.8348\n",
            "Epoch 56/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.1685 - r_square: 0.8316 - val_loss: 0.1620 - val_r_square: 0.8405\n",
            "Epoch 57/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.1628 - r_square: 0.8369 - val_loss: 0.1567 - val_r_square: 0.8456\n",
            "Epoch 58/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.1577 - r_square: 0.8421 - val_loss: 0.1521 - val_r_square: 0.8502\n",
            "Epoch 59/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.1529 - r_square: 0.8468 - val_loss: 0.1478 - val_r_square: 0.8544\n",
            "Epoch 60/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.1489 - r_square: 0.8509 - val_loss: 0.1440 - val_r_square: 0.8581\n",
            "Epoch 61/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.1452 - r_square: 0.8549 - val_loss: 0.1405 - val_r_square: 0.8615\n",
            "Epoch 62/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.1417 - r_square: 0.8580 - val_loss: 0.1373 - val_r_square: 0.8647\n",
            "Epoch 63/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.1387 - r_square: 0.8612 - val_loss: 0.1343 - val_r_square: 0.8676\n",
            "Epoch 64/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.1358 - r_square: 0.8641 - val_loss: 0.1316 - val_r_square: 0.8703\n",
            "Epoch 65/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.1331 - r_square: 0.8665 - val_loss: 0.1291 - val_r_square: 0.8728\n",
            "Epoch 66/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.1306 - r_square: 0.8692 - val_loss: 0.1267 - val_r_square: 0.8751\n",
            "Epoch 67/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.1283 - r_square: 0.8716 - val_loss: 0.1245 - val_r_square: 0.8773\n",
            "Epoch 68/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.1262 - r_square: 0.8736 - val_loss: 0.1224 - val_r_square: 0.8794\n",
            "Epoch 69/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.1241 - r_square: 0.8758 - val_loss: 0.1204 - val_r_square: 0.8813\n",
            "Epoch 70/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.1221 - r_square: 0.8778 - val_loss: 0.1185 - val_r_square: 0.8832\n",
            "Epoch 71/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.1202 - r_square: 0.8797 - val_loss: 0.1167 - val_r_square: 0.8850\n",
            "Epoch 72/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.1184 - r_square: 0.8815 - val_loss: 0.1150 - val_r_square: 0.8867\n",
            "Epoch 73/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.1167 - r_square: 0.8832 - val_loss: 0.1132 - val_r_square: 0.8885\n",
            "Epoch 74/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.1150 - r_square: 0.8851 - val_loss: 0.1115 - val_r_square: 0.8902\n",
            "Epoch 75/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.1133 - r_square: 0.8865 - val_loss: 0.1098 - val_r_square: 0.8918\n",
            "Epoch 76/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.1117 - r_square: 0.8881 - val_loss: 0.1082 - val_r_square: 0.8935\n",
            "Epoch 77/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.1100 - r_square: 0.8899 - val_loss: 0.1065 - val_r_square: 0.8951\n",
            "Epoch 78/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.1085 - r_square: 0.8912 - val_loss: 0.1049 - val_r_square: 0.8966\n",
            "Epoch 79/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.1070 - r_square: 0.8930 - val_loss: 0.1034 - val_r_square: 0.8981\n",
            "Epoch 80/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.1055 - r_square: 0.8944 - val_loss: 0.1020 - val_r_square: 0.8996\n",
            "Epoch 81/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.1041 - r_square: 0.8959 - val_loss: 0.1005 - val_r_square: 0.9010\n",
            "Epoch 82/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.1026 - r_square: 0.8973 - val_loss: 0.0991 - val_r_square: 0.9024\n",
            "Epoch 83/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.1013 - r_square: 0.8988 - val_loss: 0.0978 - val_r_square: 0.9037\n",
            "Epoch 84/2000\n",
            "1530/1530 [==============================] - 0s 20us/step - loss: 0.0999 - r_square: 0.8999 - val_loss: 0.0965 - val_r_square: 0.9050\n",
            "Epoch 85/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0986 - r_square: 0.9013 - val_loss: 0.0952 - val_r_square: 0.9062\n",
            "Epoch 86/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0973 - r_square: 0.9026 - val_loss: 0.0939 - val_r_square: 0.9075\n",
            "Epoch 87/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0961 - r_square: 0.9038 - val_loss: 0.0928 - val_r_square: 0.9086\n",
            "Epoch 88/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0949 - r_square: 0.9050 - val_loss: 0.0916 - val_r_square: 0.9098\n",
            "Epoch 89/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0937 - r_square: 0.9065 - val_loss: 0.0904 - val_r_square: 0.9110\n",
            "Epoch 90/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0925 - r_square: 0.9074 - val_loss: 0.0893 - val_r_square: 0.9120\n",
            "Epoch 91/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0913 - r_square: 0.9085 - val_loss: 0.0883 - val_r_square: 0.9131\n",
            "Epoch 92/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0903 - r_square: 0.9098 - val_loss: 0.0872 - val_r_square: 0.9141\n",
            "Epoch 93/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0892 - r_square: 0.9108 - val_loss: 0.0862 - val_r_square: 0.9151\n",
            "Epoch 94/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0881 - r_square: 0.9116 - val_loss: 0.0853 - val_r_square: 0.9160\n",
            "Epoch 95/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0871 - r_square: 0.9128 - val_loss: 0.0843 - val_r_square: 0.9170\n",
            "Epoch 96/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0861 - r_square: 0.9138 - val_loss: 0.0833 - val_r_square: 0.9180\n",
            "Epoch 97/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0852 - r_square: 0.9147 - val_loss: 0.0824 - val_r_square: 0.9189\n",
            "Epoch 98/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0842 - r_square: 0.9159 - val_loss: 0.0815 - val_r_square: 0.9198\n",
            "Epoch 99/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0833 - r_square: 0.9166 - val_loss: 0.0806 - val_r_square: 0.9206\n",
            "Epoch 100/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0823 - r_square: 0.9175 - val_loss: 0.0798 - val_r_square: 0.9215\n",
            "Epoch 101/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0814 - r_square: 0.9185 - val_loss: 0.0789 - val_r_square: 0.9223\n",
            "Epoch 102/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0806 - r_square: 0.9194 - val_loss: 0.0781 - val_r_square: 0.9231\n",
            "Epoch 103/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0797 - r_square: 0.9202 - val_loss: 0.0772 - val_r_square: 0.9240\n",
            "Epoch 104/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0788 - r_square: 0.9210 - val_loss: 0.0764 - val_r_square: 0.9248\n",
            "Epoch 105/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0780 - r_square: 0.9220 - val_loss: 0.0756 - val_r_square: 0.9255\n",
            "Epoch 106/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0772 - r_square: 0.9225 - val_loss: 0.0749 - val_r_square: 0.9263\n",
            "Epoch 107/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0764 - r_square: 0.9235 - val_loss: 0.0741 - val_r_square: 0.9271\n",
            "Epoch 108/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0757 - r_square: 0.9242 - val_loss: 0.0734 - val_r_square: 0.9277\n",
            "Epoch 109/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0749 - r_square: 0.9250 - val_loss: 0.0727 - val_r_square: 0.9284\n",
            "Epoch 110/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0742 - r_square: 0.9257 - val_loss: 0.0720 - val_r_square: 0.9291\n",
            "Epoch 111/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0735 - r_square: 0.9264 - val_loss: 0.0713 - val_r_square: 0.9298\n",
            "Epoch 112/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0728 - r_square: 0.9271 - val_loss: 0.0707 - val_r_square: 0.9304\n",
            "Epoch 113/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0721 - r_square: 0.9278 - val_loss: 0.0700 - val_r_square: 0.9311\n",
            "Epoch 114/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0715 - r_square: 0.9283 - val_loss: 0.0694 - val_r_square: 0.9317\n",
            "Epoch 115/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0708 - r_square: 0.9291 - val_loss: 0.0688 - val_r_square: 0.9323\n",
            "Epoch 116/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0702 - r_square: 0.9297 - val_loss: 0.0682 - val_r_square: 0.9329\n",
            "Epoch 117/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0696 - r_square: 0.9303 - val_loss: 0.0677 - val_r_square: 0.9334\n",
            "Epoch 118/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0690 - r_square: 0.9308 - val_loss: 0.0671 - val_r_square: 0.9339\n",
            "Epoch 119/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0685 - r_square: 0.9314 - val_loss: 0.0666 - val_r_square: 0.9345\n",
            "Epoch 120/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0679 - r_square: 0.9320 - val_loss: 0.0661 - val_r_square: 0.9350\n",
            "Epoch 121/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0674 - r_square: 0.9326 - val_loss: 0.0656 - val_r_square: 0.9355\n",
            "Epoch 122/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0669 - r_square: 0.9330 - val_loss: 0.0651 - val_r_square: 0.9360\n",
            "Epoch 123/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0663 - r_square: 0.9337 - val_loss: 0.0646 - val_r_square: 0.9365\n",
            "Epoch 124/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0658 - r_square: 0.9341 - val_loss: 0.0641 - val_r_square: 0.9370\n",
            "Epoch 125/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0653 - r_square: 0.9347 - val_loss: 0.0636 - val_r_square: 0.9374\n",
            "Epoch 126/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0649 - r_square: 0.9351 - val_loss: 0.0632 - val_r_square: 0.9378\n",
            "Epoch 127/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0644 - r_square: 0.9355 - val_loss: 0.0628 - val_r_square: 0.9382\n",
            "Epoch 128/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0640 - r_square: 0.9359 - val_loss: 0.0623 - val_r_square: 0.9387\n",
            "Epoch 129/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0635 - r_square: 0.9363 - val_loss: 0.0620 - val_r_square: 0.9390\n",
            "Epoch 130/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0631 - r_square: 0.9366 - val_loss: 0.0616 - val_r_square: 0.9394\n",
            "Epoch 131/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0627 - r_square: 0.9372 - val_loss: 0.0612 - val_r_square: 0.9398\n",
            "Epoch 132/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0623 - r_square: 0.9376 - val_loss: 0.0609 - val_r_square: 0.9401\n",
            "Epoch 133/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0619 - r_square: 0.9381 - val_loss: 0.0605 - val_r_square: 0.9404\n",
            "Epoch 134/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0616 - r_square: 0.9384 - val_loss: 0.0602 - val_r_square: 0.9408\n",
            "Epoch 135/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0612 - r_square: 0.9386 - val_loss: 0.0599 - val_r_square: 0.9411\n",
            "Epoch 136/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0608 - r_square: 0.9391 - val_loss: 0.0596 - val_r_square: 0.9414\n",
            "Epoch 137/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0605 - r_square: 0.9394 - val_loss: 0.0592 - val_r_square: 0.9417\n",
            "Epoch 138/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0602 - r_square: 0.9397 - val_loss: 0.0590 - val_r_square: 0.9420\n",
            "Epoch 139/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0599 - r_square: 0.9400 - val_loss: 0.0587 - val_r_square: 0.9422\n",
            "Epoch 140/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0596 - r_square: 0.9403 - val_loss: 0.0585 - val_r_square: 0.9424\n",
            "Epoch 141/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0593 - r_square: 0.9405 - val_loss: 0.0582 - val_r_square: 0.9427\n",
            "Epoch 142/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0590 - r_square: 0.9410 - val_loss: 0.0580 - val_r_square: 0.9430\n",
            "Epoch 143/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0587 - r_square: 0.9411 - val_loss: 0.0577 - val_r_square: 0.9432\n",
            "Epoch 144/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0585 - r_square: 0.9414 - val_loss: 0.0574 - val_r_square: 0.9435\n",
            "Epoch 145/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0582 - r_square: 0.9417 - val_loss: 0.0572 - val_r_square: 0.9437\n",
            "Epoch 146/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0579 - r_square: 0.9420 - val_loss: 0.0570 - val_r_square: 0.9439\n",
            "Epoch 147/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0577 - r_square: 0.9422 - val_loss: 0.0568 - val_r_square: 0.9441\n",
            "Epoch 148/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0574 - r_square: 0.9425 - val_loss: 0.0566 - val_r_square: 0.9443\n",
            "Epoch 149/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0572 - r_square: 0.9426 - val_loss: 0.0564 - val_r_square: 0.9445\n",
            "Epoch 150/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0570 - r_square: 0.9429 - val_loss: 0.0562 - val_r_square: 0.9447\n",
            "Epoch 151/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0567 - r_square: 0.9432 - val_loss: 0.0560 - val_r_square: 0.9449\n",
            "Epoch 152/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0565 - r_square: 0.9434 - val_loss: 0.0559 - val_r_square: 0.9450\n",
            "Epoch 153/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0563 - r_square: 0.9436 - val_loss: 0.0557 - val_r_square: 0.9452\n",
            "Epoch 154/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0561 - r_square: 0.9439 - val_loss: 0.0555 - val_r_square: 0.9454\n",
            "Epoch 155/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0559 - r_square: 0.9440 - val_loss: 0.0553 - val_r_square: 0.9455\n",
            "Epoch 156/2000\n",
            "1530/1530 [==============================] - 0s 20us/step - loss: 0.0557 - r_square: 0.9443 - val_loss: 0.0552 - val_r_square: 0.9457\n",
            "Epoch 157/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0555 - r_square: 0.9444 - val_loss: 0.0550 - val_r_square: 0.9458\n",
            "Epoch 158/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0553 - r_square: 0.9445 - val_loss: 0.0549 - val_r_square: 0.9460\n",
            "Epoch 159/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0551 - r_square: 0.9448 - val_loss: 0.0547 - val_r_square: 0.9461\n",
            "Epoch 160/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0550 - r_square: 0.9449 - val_loss: 0.0546 - val_r_square: 0.9463\n",
            "Epoch 161/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0548 - r_square: 0.9450 - val_loss: 0.0544 - val_r_square: 0.9465\n",
            "Epoch 162/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0546 - r_square: 0.9454 - val_loss: 0.0543 - val_r_square: 0.9466\n",
            "Epoch 163/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0545 - r_square: 0.9455 - val_loss: 0.0542 - val_r_square: 0.9467\n",
            "Epoch 164/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0543 - r_square: 0.9456 - val_loss: 0.0541 - val_r_square: 0.9468\n",
            "Epoch 165/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0542 - r_square: 0.9458 - val_loss: 0.0539 - val_r_square: 0.9470\n",
            "Epoch 166/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0540 - r_square: 0.9458 - val_loss: 0.0538 - val_r_square: 0.9471\n",
            "Epoch 167/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0538 - r_square: 0.9461 - val_loss: 0.0537 - val_r_square: 0.9472\n",
            "Epoch 168/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0537 - r_square: 0.9462 - val_loss: 0.0536 - val_r_square: 0.9473\n",
            "Epoch 169/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0536 - r_square: 0.9464 - val_loss: 0.0534 - val_r_square: 0.9474\n",
            "Epoch 170/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0535 - r_square: 0.9463 - val_loss: 0.0533 - val_r_square: 0.9475\n",
            "Epoch 171/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0533 - r_square: 0.9464 - val_loss: 0.0532 - val_r_square: 0.9477\n",
            "Epoch 172/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0532 - r_square: 0.9467 - val_loss: 0.0531 - val_r_square: 0.9478\n",
            "Epoch 173/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0531 - r_square: 0.9468 - val_loss: 0.0530 - val_r_square: 0.9478\n",
            "Epoch 174/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0529 - r_square: 0.9470 - val_loss: 0.0529 - val_r_square: 0.9480\n",
            "Epoch 175/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0528 - r_square: 0.9471 - val_loss: 0.0528 - val_r_square: 0.9481\n",
            "Epoch 176/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0527 - r_square: 0.9469 - val_loss: 0.0527 - val_r_square: 0.9482\n",
            "Epoch 177/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0526 - r_square: 0.9474 - val_loss: 0.0526 - val_r_square: 0.9483\n",
            "Epoch 178/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0524 - r_square: 0.9475 - val_loss: 0.0524 - val_r_square: 0.9484\n",
            "Epoch 179/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0523 - r_square: 0.9476 - val_loss: 0.0524 - val_r_square: 0.9485\n",
            "Epoch 180/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0522 - r_square: 0.9477 - val_loss: 0.0522 - val_r_square: 0.9486\n",
            "Epoch 181/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0521 - r_square: 0.9478 - val_loss: 0.0521 - val_r_square: 0.9487\n",
            "Epoch 182/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0520 - r_square: 0.9479 - val_loss: 0.0520 - val_r_square: 0.9488\n",
            "Epoch 183/2000\n",
            "1530/1530 [==============================] - 0s 20us/step - loss: 0.0519 - r_square: 0.9480 - val_loss: 0.0519 - val_r_square: 0.9489\n",
            "Epoch 184/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0518 - r_square: 0.9482 - val_loss: 0.0518 - val_r_square: 0.9490\n",
            "Epoch 185/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0517 - r_square: 0.9481 - val_loss: 0.0518 - val_r_square: 0.9491\n",
            "Epoch 186/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0516 - r_square: 0.9483 - val_loss: 0.0517 - val_r_square: 0.9491\n",
            "Epoch 187/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0515 - r_square: 0.9485 - val_loss: 0.0516 - val_r_square: 0.9492\n",
            "Epoch 188/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0514 - r_square: 0.9485 - val_loss: 0.0515 - val_r_square: 0.9493\n",
            "Epoch 189/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0513 - r_square: 0.9487 - val_loss: 0.0514 - val_r_square: 0.9494\n",
            "Epoch 190/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0512 - r_square: 0.9486 - val_loss: 0.0513 - val_r_square: 0.9495\n",
            "Epoch 191/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0511 - r_square: 0.9488 - val_loss: 0.0513 - val_r_square: 0.9496\n",
            "Epoch 192/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0510 - r_square: 0.9488 - val_loss: 0.0511 - val_r_square: 0.9497\n",
            "Epoch 193/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0509 - r_square: 0.9490 - val_loss: 0.0510 - val_r_square: 0.9498\n",
            "Epoch 194/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0508 - r_square: 0.9492 - val_loss: 0.0510 - val_r_square: 0.9499\n",
            "Epoch 195/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0507 - r_square: 0.9492 - val_loss: 0.0509 - val_r_square: 0.9500\n",
            "Epoch 196/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0506 - r_square: 0.9493 - val_loss: 0.0508 - val_r_square: 0.9500\n",
            "Epoch 197/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0505 - r_square: 0.9494 - val_loss: 0.0507 - val_r_square: 0.9502\n",
            "Epoch 198/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0504 - r_square: 0.9494 - val_loss: 0.0506 - val_r_square: 0.9502\n",
            "Epoch 199/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0503 - r_square: 0.9496 - val_loss: 0.0505 - val_r_square: 0.9503\n",
            "Epoch 200/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0502 - r_square: 0.9497 - val_loss: 0.0505 - val_r_square: 0.9503\n",
            "Epoch 201/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0501 - r_square: 0.9499 - val_loss: 0.0504 - val_r_square: 0.9504\n",
            "Epoch 202/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0501 - r_square: 0.9498 - val_loss: 0.0503 - val_r_square: 0.9505\n",
            "Epoch 203/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0500 - r_square: 0.9500 - val_loss: 0.0502 - val_r_square: 0.9507\n",
            "Epoch 204/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0499 - r_square: 0.9501 - val_loss: 0.0501 - val_r_square: 0.9507\n",
            "Epoch 205/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0498 - r_square: 0.9501 - val_loss: 0.0500 - val_r_square: 0.9508\n",
            "Epoch 206/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0497 - r_square: 0.9502 - val_loss: 0.0500 - val_r_square: 0.9508\n",
            "Epoch 207/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0496 - r_square: 0.9503 - val_loss: 0.0499 - val_r_square: 0.9509\n",
            "Epoch 208/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0495 - r_square: 0.9505 - val_loss: 0.0499 - val_r_square: 0.9509\n",
            "Epoch 209/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0494 - r_square: 0.9505 - val_loss: 0.0498 - val_r_square: 0.9510\n",
            "Epoch 210/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0494 - r_square: 0.9506 - val_loss: 0.0497 - val_r_square: 0.9511\n",
            "Epoch 211/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0493 - r_square: 0.9505 - val_loss: 0.0496 - val_r_square: 0.9512\n",
            "Epoch 212/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0492 - r_square: 0.9507 - val_loss: 0.0496 - val_r_square: 0.9512\n",
            "Epoch 213/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0491 - r_square: 0.9509 - val_loss: 0.0495 - val_r_square: 0.9513\n",
            "Epoch 214/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0490 - r_square: 0.9509 - val_loss: 0.0494 - val_r_square: 0.9514\n",
            "Epoch 215/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0490 - r_square: 0.9510 - val_loss: 0.0493 - val_r_square: 0.9515\n",
            "Epoch 216/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0490 - r_square: 0.9510 - val_loss: 0.0493 - val_r_square: 0.9515\n",
            "Epoch 217/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0488 - r_square: 0.9511 - val_loss: 0.0492 - val_r_square: 0.9516\n",
            "Epoch 218/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0488 - r_square: 0.9512 - val_loss: 0.0491 - val_r_square: 0.9517\n",
            "Epoch 219/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0487 - r_square: 0.9513 - val_loss: 0.0491 - val_r_square: 0.9517\n",
            "Epoch 220/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0486 - r_square: 0.9513 - val_loss: 0.0490 - val_r_square: 0.9518\n",
            "Epoch 221/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0485 - r_square: 0.9514 - val_loss: 0.0489 - val_r_square: 0.9519\n",
            "Epoch 222/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0484 - r_square: 0.9515 - val_loss: 0.0488 - val_r_square: 0.9520\n",
            "Epoch 223/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0484 - r_square: 0.9516 - val_loss: 0.0487 - val_r_square: 0.9521\n",
            "Epoch 224/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0483 - r_square: 0.9515 - val_loss: 0.0487 - val_r_square: 0.9521\n",
            "Epoch 225/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0482 - r_square: 0.9518 - val_loss: 0.0486 - val_r_square: 0.9522\n",
            "Epoch 226/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0482 - r_square: 0.9518 - val_loss: 0.0486 - val_r_square: 0.9522\n",
            "Epoch 227/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0481 - r_square: 0.9518 - val_loss: 0.0485 - val_r_square: 0.9523\n",
            "Epoch 228/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0481 - r_square: 0.9519 - val_loss: 0.0485 - val_r_square: 0.9523\n",
            "Epoch 229/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0480 - r_square: 0.9520 - val_loss: 0.0483 - val_r_square: 0.9525\n",
            "Epoch 230/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0479 - r_square: 0.9520 - val_loss: 0.0483 - val_r_square: 0.9525\n",
            "Epoch 231/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0478 - r_square: 0.9521 - val_loss: 0.0482 - val_r_square: 0.9526\n",
            "Epoch 232/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0478 - r_square: 0.9521 - val_loss: 0.0481 - val_r_square: 0.9527\n",
            "Epoch 233/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0477 - r_square: 0.9522 - val_loss: 0.0480 - val_r_square: 0.9527\n",
            "Epoch 234/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0477 - r_square: 0.9523 - val_loss: 0.0480 - val_r_square: 0.9528\n",
            "Epoch 235/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0476 - r_square: 0.9524 - val_loss: 0.0479 - val_r_square: 0.9529\n",
            "Epoch 236/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0475 - r_square: 0.9523 - val_loss: 0.0479 - val_r_square: 0.9529\n",
            "Epoch 237/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0474 - r_square: 0.9525 - val_loss: 0.0478 - val_r_square: 0.9530\n",
            "Epoch 238/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0474 - r_square: 0.9526 - val_loss: 0.0478 - val_r_square: 0.9530\n",
            "Epoch 239/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0473 - r_square: 0.9526 - val_loss: 0.0477 - val_r_square: 0.9531\n",
            "Epoch 240/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0473 - r_square: 0.9526 - val_loss: 0.0476 - val_r_square: 0.9532\n",
            "Epoch 241/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0472 - r_square: 0.9528 - val_loss: 0.0476 - val_r_square: 0.9532\n",
            "Epoch 242/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0471 - r_square: 0.9528 - val_loss: 0.0475 - val_r_square: 0.9533\n",
            "Epoch 243/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0471 - r_square: 0.9528 - val_loss: 0.0474 - val_r_square: 0.9534\n",
            "Epoch 244/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0470 - r_square: 0.9529 - val_loss: 0.0473 - val_r_square: 0.9534\n",
            "Epoch 245/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0470 - r_square: 0.9528 - val_loss: 0.0473 - val_r_square: 0.9535\n",
            "Epoch 246/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0469 - r_square: 0.9530 - val_loss: 0.0473 - val_r_square: 0.9535\n",
            "Epoch 247/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0468 - r_square: 0.9531 - val_loss: 0.0472 - val_r_square: 0.9536\n",
            "Epoch 248/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0468 - r_square: 0.9532 - val_loss: 0.0472 - val_r_square: 0.9536\n",
            "Epoch 249/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0468 - r_square: 0.9532 - val_loss: 0.0471 - val_r_square: 0.9537\n",
            "Epoch 250/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0467 - r_square: 0.9532 - val_loss: 0.0470 - val_r_square: 0.9537\n",
            "Epoch 251/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0466 - r_square: 0.9532 - val_loss: 0.0470 - val_r_square: 0.9538\n",
            "Epoch 252/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0465 - r_square: 0.9534 - val_loss: 0.0469 - val_r_square: 0.9538\n",
            "Epoch 253/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0465 - r_square: 0.9535 - val_loss: 0.0469 - val_r_square: 0.9539\n",
            "Epoch 254/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0465 - r_square: 0.9535 - val_loss: 0.0468 - val_r_square: 0.9540\n",
            "Epoch 255/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0464 - r_square: 0.9535 - val_loss: 0.0467 - val_r_square: 0.9540\n",
            "Epoch 256/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0463 - r_square: 0.9536 - val_loss: 0.0467 - val_r_square: 0.9541\n",
            "Epoch 257/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0463 - r_square: 0.9536 - val_loss: 0.0466 - val_r_square: 0.9542\n",
            "Epoch 258/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0462 - r_square: 0.9538 - val_loss: 0.0465 - val_r_square: 0.9543\n",
            "Epoch 259/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0462 - r_square: 0.9538 - val_loss: 0.0465 - val_r_square: 0.9543\n",
            "Epoch 260/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0461 - r_square: 0.9538 - val_loss: 0.0464 - val_r_square: 0.9544\n",
            "Epoch 261/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0460 - r_square: 0.9539 - val_loss: 0.0463 - val_r_square: 0.9544\n",
            "Epoch 262/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0460 - r_square: 0.9540 - val_loss: 0.0462 - val_r_square: 0.9545\n",
            "Epoch 263/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0459 - r_square: 0.9540 - val_loss: 0.0462 - val_r_square: 0.9546\n",
            "Epoch 264/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0458 - r_square: 0.9540 - val_loss: 0.0461 - val_r_square: 0.9546\n",
            "Epoch 265/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0458 - r_square: 0.9541 - val_loss: 0.0460 - val_r_square: 0.9547\n",
            "Epoch 266/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0457 - r_square: 0.9542 - val_loss: 0.0460 - val_r_square: 0.9547\n",
            "Epoch 267/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0457 - r_square: 0.9542 - val_loss: 0.0459 - val_r_square: 0.9548\n",
            "Epoch 268/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0456 - r_square: 0.9544 - val_loss: 0.0459 - val_r_square: 0.9549\n",
            "Epoch 269/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0455 - r_square: 0.9544 - val_loss: 0.0458 - val_r_square: 0.9549\n",
            "Epoch 270/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0455 - r_square: 0.9544 - val_loss: 0.0457 - val_r_square: 0.9550\n",
            "Epoch 271/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0454 - r_square: 0.9545 - val_loss: 0.0457 - val_r_square: 0.9551\n",
            "Epoch 272/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0454 - r_square: 0.9546 - val_loss: 0.0455 - val_r_square: 0.9552\n",
            "Epoch 273/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0453 - r_square: 0.9546 - val_loss: 0.0455 - val_r_square: 0.9552\n",
            "Epoch 274/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0453 - r_square: 0.9547 - val_loss: 0.0454 - val_r_square: 0.9553\n",
            "Epoch 275/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0452 - r_square: 0.9548 - val_loss: 0.0453 - val_r_square: 0.9554\n",
            "Epoch 276/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0451 - r_square: 0.9548 - val_loss: 0.0452 - val_r_square: 0.9555\n",
            "Epoch 277/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0451 - r_square: 0.9547 - val_loss: 0.0452 - val_r_square: 0.9555\n",
            "Epoch 278/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0450 - r_square: 0.9549 - val_loss: 0.0452 - val_r_square: 0.9556\n",
            "Epoch 279/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0450 - r_square: 0.9550 - val_loss: 0.0451 - val_r_square: 0.9556\n",
            "Epoch 280/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0449 - r_square: 0.9550 - val_loss: 0.0450 - val_r_square: 0.9557\n",
            "Epoch 281/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0448 - r_square: 0.9551 - val_loss: 0.0450 - val_r_square: 0.9558\n",
            "Epoch 282/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0448 - r_square: 0.9551 - val_loss: 0.0449 - val_r_square: 0.9559\n",
            "Epoch 283/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0447 - r_square: 0.9552 - val_loss: 0.0448 - val_r_square: 0.9559\n",
            "Epoch 284/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0447 - r_square: 0.9553 - val_loss: 0.0448 - val_r_square: 0.9559\n",
            "Epoch 285/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0447 - r_square: 0.9553 - val_loss: 0.0447 - val_r_square: 0.9560\n",
            "Epoch 286/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0446 - r_square: 0.9554 - val_loss: 0.0446 - val_r_square: 0.9561\n",
            "Epoch 287/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0445 - r_square: 0.9554 - val_loss: 0.0446 - val_r_square: 0.9561\n",
            "Epoch 288/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0445 - r_square: 0.9554 - val_loss: 0.0445 - val_r_square: 0.9562\n",
            "Epoch 289/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0444 - r_square: 0.9553 - val_loss: 0.0445 - val_r_square: 0.9562\n",
            "Epoch 290/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0444 - r_square: 0.9555 - val_loss: 0.0444 - val_r_square: 0.9563\n",
            "Epoch 291/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0443 - r_square: 0.9556 - val_loss: 0.0443 - val_r_square: 0.9564\n",
            "Epoch 292/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0443 - r_square: 0.9557 - val_loss: 0.0443 - val_r_square: 0.9565\n",
            "Epoch 293/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0442 - r_square: 0.9557 - val_loss: 0.0442 - val_r_square: 0.9565\n",
            "Epoch 294/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0441 - r_square: 0.9558 - val_loss: 0.0441 - val_r_square: 0.9566\n",
            "Epoch 295/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0441 - r_square: 0.9559 - val_loss: 0.0441 - val_r_square: 0.9566\n",
            "Epoch 296/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0440 - r_square: 0.9558 - val_loss: 0.0440 - val_r_square: 0.9567\n",
            "Epoch 297/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0440 - r_square: 0.9559 - val_loss: 0.0439 - val_r_square: 0.9568\n",
            "Epoch 298/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0440 - r_square: 0.9560 - val_loss: 0.0439 - val_r_square: 0.9568\n",
            "Epoch 299/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0439 - r_square: 0.9560 - val_loss: 0.0438 - val_r_square: 0.9569\n",
            "Epoch 300/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0438 - r_square: 0.9561 - val_loss: 0.0437 - val_r_square: 0.9570\n",
            "Epoch 301/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0437 - r_square: 0.9562 - val_loss: 0.0437 - val_r_square: 0.9570\n",
            "Epoch 302/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0437 - r_square: 0.9563 - val_loss: 0.0436 - val_r_square: 0.9571\n",
            "Epoch 303/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0437 - r_square: 0.9563 - val_loss: 0.0436 - val_r_square: 0.9571\n",
            "Epoch 304/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0436 - r_square: 0.9564 - val_loss: 0.0435 - val_r_square: 0.9572\n",
            "Epoch 305/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0435 - r_square: 0.9564 - val_loss: 0.0435 - val_r_square: 0.9572\n",
            "Epoch 306/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0434 - r_square: 0.9565 - val_loss: 0.0434 - val_r_square: 0.9573\n",
            "Epoch 307/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0434 - r_square: 0.9566 - val_loss: 0.0433 - val_r_square: 0.9574\n",
            "Epoch 308/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0433 - r_square: 0.9567 - val_loss: 0.0432 - val_r_square: 0.9575\n",
            "Epoch 309/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0432 - r_square: 0.9566 - val_loss: 0.0432 - val_r_square: 0.9575\n",
            "Epoch 310/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0432 - r_square: 0.9567 - val_loss: 0.0431 - val_r_square: 0.9576\n",
            "Epoch 311/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0431 - r_square: 0.9567 - val_loss: 0.0430 - val_r_square: 0.9577\n",
            "Epoch 312/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0431 - r_square: 0.9569 - val_loss: 0.0430 - val_r_square: 0.9577\n",
            "Epoch 313/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0430 - r_square: 0.9570 - val_loss: 0.0429 - val_r_square: 0.9578\n",
            "Epoch 314/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0429 - r_square: 0.9570 - val_loss: 0.0429 - val_r_square: 0.9578\n",
            "Epoch 315/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0429 - r_square: 0.9570 - val_loss: 0.0428 - val_r_square: 0.9579\n",
            "Epoch 316/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0428 - r_square: 0.9572 - val_loss: 0.0427 - val_r_square: 0.9580\n",
            "Epoch 317/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0427 - r_square: 0.9572 - val_loss: 0.0426 - val_r_square: 0.9581\n",
            "Epoch 318/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0427 - r_square: 0.9572 - val_loss: 0.0425 - val_r_square: 0.9582\n",
            "Epoch 319/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0426 - r_square: 0.9574 - val_loss: 0.0425 - val_r_square: 0.9582\n",
            "Epoch 320/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0426 - r_square: 0.9573 - val_loss: 0.0423 - val_r_square: 0.9584\n",
            "Epoch 321/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0425 - r_square: 0.9573 - val_loss: 0.0423 - val_r_square: 0.9584\n",
            "Epoch 322/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0424 - r_square: 0.9573 - val_loss: 0.0422 - val_r_square: 0.9585\n",
            "Epoch 323/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0423 - r_square: 0.9576 - val_loss: 0.0422 - val_r_square: 0.9585\n",
            "Epoch 324/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0423 - r_square: 0.9577 - val_loss: 0.0421 - val_r_square: 0.9586\n",
            "Epoch 325/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0422 - r_square: 0.9577 - val_loss: 0.0420 - val_r_square: 0.9587\n",
            "Epoch 326/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0421 - r_square: 0.9579 - val_loss: 0.0419 - val_r_square: 0.9588\n",
            "Epoch 327/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0421 - r_square: 0.9578 - val_loss: 0.0418 - val_r_square: 0.9589\n",
            "Epoch 328/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0420 - r_square: 0.9579 - val_loss: 0.0418 - val_r_square: 0.9589\n",
            "Epoch 329/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0419 - r_square: 0.9580 - val_loss: 0.0417 - val_r_square: 0.9590\n",
            "Epoch 330/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0419 - r_square: 0.9580 - val_loss: 0.0416 - val_r_square: 0.9591\n",
            "Epoch 331/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0418 - r_square: 0.9582 - val_loss: 0.0415 - val_r_square: 0.9591\n",
            "Epoch 332/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0417 - r_square: 0.9582 - val_loss: 0.0414 - val_r_square: 0.9593\n",
            "Epoch 333/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0417 - r_square: 0.9583 - val_loss: 0.0413 - val_r_square: 0.9594\n",
            "Epoch 334/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0416 - r_square: 0.9584 - val_loss: 0.0412 - val_r_square: 0.9595\n",
            "Epoch 335/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0416 - r_square: 0.9583 - val_loss: 0.0412 - val_r_square: 0.9595\n",
            "Epoch 336/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0415 - r_square: 0.9585 - val_loss: 0.0410 - val_r_square: 0.9596\n",
            "Epoch 337/2000\n",
            "1530/1530 [==============================] - 0s 43us/step - loss: 0.0414 - r_square: 0.9585 - val_loss: 0.0409 - val_r_square: 0.9597\n",
            "Epoch 338/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0413 - r_square: 0.9586 - val_loss: 0.0409 - val_r_square: 0.9598\n",
            "Epoch 339/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0413 - r_square: 0.9587 - val_loss: 0.0408 - val_r_square: 0.9599\n",
            "Epoch 340/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0412 - r_square: 0.9588 - val_loss: 0.0406 - val_r_square: 0.9600\n",
            "Epoch 341/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0411 - r_square: 0.9589 - val_loss: 0.0406 - val_r_square: 0.9601\n",
            "Epoch 342/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0410 - r_square: 0.9589 - val_loss: 0.0405 - val_r_square: 0.9602\n",
            "Epoch 343/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0410 - r_square: 0.9590 - val_loss: 0.0404 - val_r_square: 0.9603\n",
            "Epoch 344/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0409 - r_square: 0.9591 - val_loss: 0.0403 - val_r_square: 0.9604\n",
            "Epoch 345/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0408 - r_square: 0.9591 - val_loss: 0.0402 - val_r_square: 0.9604\n",
            "Epoch 346/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0407 - r_square: 0.9592 - val_loss: 0.0401 - val_r_square: 0.9606\n",
            "Epoch 347/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0407 - r_square: 0.9593 - val_loss: 0.0400 - val_r_square: 0.9607\n",
            "Epoch 348/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0406 - r_square: 0.9591 - val_loss: 0.0399 - val_r_square: 0.9607\n",
            "Epoch 349/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0405 - r_square: 0.9594 - val_loss: 0.0398 - val_r_square: 0.9609\n",
            "Epoch 350/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0404 - r_square: 0.9593 - val_loss: 0.0397 - val_r_square: 0.9610\n",
            "Epoch 351/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0403 - r_square: 0.9596 - val_loss: 0.0396 - val_r_square: 0.9611\n",
            "Epoch 352/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0402 - r_square: 0.9597 - val_loss: 0.0395 - val_r_square: 0.9612\n",
            "Epoch 353/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0402 - r_square: 0.9598 - val_loss: 0.0393 - val_r_square: 0.9613\n",
            "Epoch 354/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0401 - r_square: 0.9598 - val_loss: 0.0393 - val_r_square: 0.9614\n",
            "Epoch 355/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0399 - r_square: 0.9600 - val_loss: 0.0392 - val_r_square: 0.9615\n",
            "Epoch 356/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0399 - r_square: 0.9601 - val_loss: 0.0391 - val_r_square: 0.9616\n",
            "Epoch 357/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0398 - r_square: 0.9602 - val_loss: 0.0389 - val_r_square: 0.9618\n",
            "Epoch 358/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0396 - r_square: 0.9603 - val_loss: 0.0388 - val_r_square: 0.9619\n",
            "Epoch 359/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0395 - r_square: 0.9604 - val_loss: 0.0387 - val_r_square: 0.9620\n",
            "Epoch 360/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0395 - r_square: 0.9605 - val_loss: 0.0386 - val_r_square: 0.9621\n",
            "Epoch 361/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0393 - r_square: 0.9606 - val_loss: 0.0384 - val_r_square: 0.9622\n",
            "Epoch 362/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0392 - r_square: 0.9607 - val_loss: 0.0382 - val_r_square: 0.9624\n",
            "Epoch 363/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0391 - r_square: 0.9607 - val_loss: 0.0381 - val_r_square: 0.9626\n",
            "Epoch 364/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0390 - r_square: 0.9608 - val_loss: 0.0380 - val_r_square: 0.9627\n",
            "Epoch 365/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0389 - r_square: 0.9611 - val_loss: 0.0378 - val_r_square: 0.9628\n",
            "Epoch 366/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0388 - r_square: 0.9611 - val_loss: 0.0376 - val_r_square: 0.9630\n",
            "Epoch 367/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0386 - r_square: 0.9613 - val_loss: 0.0375 - val_r_square: 0.9631\n",
            "Epoch 368/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0385 - r_square: 0.9614 - val_loss: 0.0374 - val_r_square: 0.9632\n",
            "Epoch 369/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0384 - r_square: 0.9615 - val_loss: 0.0372 - val_r_square: 0.9634\n",
            "Epoch 370/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0383 - r_square: 0.9617 - val_loss: 0.0370 - val_r_square: 0.9636\n",
            "Epoch 371/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0382 - r_square: 0.9618 - val_loss: 0.0368 - val_r_square: 0.9638\n",
            "Epoch 372/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0380 - r_square: 0.9619 - val_loss: 0.0366 - val_r_square: 0.9640\n",
            "Epoch 373/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0379 - r_square: 0.9621 - val_loss: 0.0364 - val_r_square: 0.9642\n",
            "Epoch 374/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0377 - r_square: 0.9622 - val_loss: 0.0362 - val_r_square: 0.9644\n",
            "Epoch 375/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0375 - r_square: 0.9624 - val_loss: 0.0360 - val_r_square: 0.9646\n",
            "Epoch 376/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0374 - r_square: 0.9626 - val_loss: 0.0358 - val_r_square: 0.9648\n",
            "Epoch 377/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0372 - r_square: 0.9628 - val_loss: 0.0356 - val_r_square: 0.9650\n",
            "Epoch 378/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0370 - r_square: 0.9629 - val_loss: 0.0353 - val_r_square: 0.9653\n",
            "Epoch 379/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0369 - r_square: 0.9630 - val_loss: 0.0352 - val_r_square: 0.9654\n",
            "Epoch 380/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0367 - r_square: 0.9632 - val_loss: 0.0349 - val_r_square: 0.9657\n",
            "Epoch 381/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0365 - r_square: 0.9633 - val_loss: 0.0347 - val_r_square: 0.9659\n",
            "Epoch 382/2000\n",
            "1530/1530 [==============================] - 0s 43us/step - loss: 0.0363 - r_square: 0.9636 - val_loss: 0.0345 - val_r_square: 0.9661\n",
            "Epoch 383/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0361 - r_square: 0.9638 - val_loss: 0.0343 - val_r_square: 0.9663\n",
            "Epoch 384/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0359 - r_square: 0.9640 - val_loss: 0.0340 - val_r_square: 0.9665\n",
            "Epoch 385/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0357 - r_square: 0.9643 - val_loss: 0.0338 - val_r_square: 0.9668\n",
            "Epoch 386/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0355 - r_square: 0.9643 - val_loss: 0.0336 - val_r_square: 0.9670\n",
            "Epoch 387/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0353 - r_square: 0.9647 - val_loss: 0.0334 - val_r_square: 0.9672\n",
            "Epoch 388/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0351 - r_square: 0.9648 - val_loss: 0.0331 - val_r_square: 0.9675\n",
            "Epoch 389/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0348 - r_square: 0.9651 - val_loss: 0.0328 - val_r_square: 0.9677\n",
            "Epoch 390/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0346 - r_square: 0.9654 - val_loss: 0.0326 - val_r_square: 0.9679\n",
            "Epoch 391/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0343 - r_square: 0.9656 - val_loss: 0.0323 - val_r_square: 0.9682\n",
            "Epoch 392/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0340 - r_square: 0.9659 - val_loss: 0.0320 - val_r_square: 0.9685\n",
            "Epoch 393/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0337 - r_square: 0.9662 - val_loss: 0.0318 - val_r_square: 0.9688\n",
            "Epoch 394/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0334 - r_square: 0.9665 - val_loss: 0.0315 - val_r_square: 0.9690\n",
            "Epoch 395/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0332 - r_square: 0.9668 - val_loss: 0.0312 - val_r_square: 0.9693\n",
            "Epoch 396/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0329 - r_square: 0.9671 - val_loss: 0.0309 - val_r_square: 0.9696\n",
            "Epoch 397/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0325 - r_square: 0.9674 - val_loss: 0.0306 - val_r_square: 0.9699\n",
            "Epoch 398/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0322 - r_square: 0.9677 - val_loss: 0.0304 - val_r_square: 0.9701\n",
            "Epoch 399/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0319 - r_square: 0.9680 - val_loss: 0.0300 - val_r_square: 0.9705\n",
            "Epoch 400/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0316 - r_square: 0.9684 - val_loss: 0.0297 - val_r_square: 0.9708\n",
            "Epoch 401/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0312 - r_square: 0.9687 - val_loss: 0.0293 - val_r_square: 0.9711\n",
            "Epoch 402/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0309 - r_square: 0.9691 - val_loss: 0.0291 - val_r_square: 0.9714\n",
            "Epoch 403/2000\n",
            "1530/1530 [==============================] - 0s 43us/step - loss: 0.0305 - r_square: 0.9695 - val_loss: 0.0288 - val_r_square: 0.9717\n",
            "Epoch 404/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0301 - r_square: 0.9699 - val_loss: 0.0284 - val_r_square: 0.9720\n",
            "Epoch 405/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0298 - r_square: 0.9702 - val_loss: 0.0281 - val_r_square: 0.9723\n",
            "Epoch 406/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0294 - r_square: 0.9705 - val_loss: 0.0278 - val_r_square: 0.9726\n",
            "Epoch 407/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0290 - r_square: 0.9709 - val_loss: 0.0275 - val_r_square: 0.9729\n",
            "Epoch 408/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0286 - r_square: 0.9714 - val_loss: 0.0272 - val_r_square: 0.9732\n",
            "Epoch 409/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0282 - r_square: 0.9717 - val_loss: 0.0269 - val_r_square: 0.9735\n",
            "Epoch 410/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0277 - r_square: 0.9722 - val_loss: 0.0265 - val_r_square: 0.9739\n",
            "Epoch 411/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0274 - r_square: 0.9726 - val_loss: 0.0262 - val_r_square: 0.9742\n",
            "Epoch 412/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0269 - r_square: 0.9730 - val_loss: 0.0258 - val_r_square: 0.9746\n",
            "Epoch 413/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0265 - r_square: 0.9735 - val_loss: 0.0254 - val_r_square: 0.9750\n",
            "Epoch 414/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0260 - r_square: 0.9740 - val_loss: 0.0250 - val_r_square: 0.9754\n",
            "Epoch 415/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0255 - r_square: 0.9744 - val_loss: 0.0246 - val_r_square: 0.9758\n",
            "Epoch 416/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0251 - r_square: 0.9749 - val_loss: 0.0242 - val_r_square: 0.9761\n",
            "Epoch 417/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0246 - r_square: 0.9754 - val_loss: 0.0239 - val_r_square: 0.9765\n",
            "Epoch 418/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0241 - r_square: 0.9758 - val_loss: 0.0235 - val_r_square: 0.9768\n",
            "Epoch 419/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0237 - r_square: 0.9763 - val_loss: 0.0231 - val_r_square: 0.9772\n",
            "Epoch 420/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0232 - r_square: 0.9768 - val_loss: 0.0228 - val_r_square: 0.9776\n",
            "Epoch 421/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0228 - r_square: 0.9772 - val_loss: 0.0224 - val_r_square: 0.9779\n",
            "Epoch 422/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0223 - r_square: 0.9777 - val_loss: 0.0220 - val_r_square: 0.9783\n",
            "Epoch 423/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0219 - r_square: 0.9781 - val_loss: 0.0217 - val_r_square: 0.9786\n",
            "Epoch 424/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0215 - r_square: 0.9785 - val_loss: 0.0213 - val_r_square: 0.9789\n",
            "Epoch 425/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0211 - r_square: 0.9789 - val_loss: 0.0210 - val_r_square: 0.9793\n",
            "Epoch 426/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0207 - r_square: 0.9793 - val_loss: 0.0207 - val_r_square: 0.9796\n",
            "Epoch 427/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0203 - r_square: 0.9797 - val_loss: 0.0203 - val_r_square: 0.9800\n",
            "Epoch 428/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0199 - r_square: 0.9801 - val_loss: 0.0200 - val_r_square: 0.9803\n",
            "Epoch 429/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0195 - r_square: 0.9805 - val_loss: 0.0196 - val_r_square: 0.9807\n",
            "Epoch 430/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0192 - r_square: 0.9808 - val_loss: 0.0192 - val_r_square: 0.9810\n",
            "Epoch 431/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0188 - r_square: 0.9812 - val_loss: 0.0188 - val_r_square: 0.9814\n",
            "Epoch 432/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0184 - r_square: 0.9815 - val_loss: 0.0185 - val_r_square: 0.9817\n",
            "Epoch 433/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0181 - r_square: 0.9819 - val_loss: 0.0182 - val_r_square: 0.9821\n",
            "Epoch 434/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0177 - r_square: 0.9823 - val_loss: 0.0178 - val_r_square: 0.9825\n",
            "Epoch 435/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0174 - r_square: 0.9825 - val_loss: 0.0175 - val_r_square: 0.9828\n",
            "Epoch 436/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0171 - r_square: 0.9829 - val_loss: 0.0172 - val_r_square: 0.9831\n",
            "Epoch 437/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0168 - r_square: 0.9832 - val_loss: 0.0168 - val_r_square: 0.9834\n",
            "Epoch 438/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0165 - r_square: 0.9835 - val_loss: 0.0165 - val_r_square: 0.9837\n",
            "Epoch 439/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0162 - r_square: 0.9838 - val_loss: 0.0162 - val_r_square: 0.9840\n",
            "Epoch 440/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0159 - r_square: 0.9840 - val_loss: 0.0159 - val_r_square: 0.9843\n",
            "Epoch 441/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0157 - r_square: 0.9843 - val_loss: 0.0156 - val_r_square: 0.9846\n",
            "Epoch 442/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0154 - r_square: 0.9845 - val_loss: 0.0153 - val_r_square: 0.9849\n",
            "Epoch 443/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0152 - r_square: 0.9848 - val_loss: 0.0151 - val_r_square: 0.9851\n",
            "Epoch 444/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0150 - r_square: 0.9850 - val_loss: 0.0148 - val_r_square: 0.9854\n",
            "Epoch 445/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0148 - r_square: 0.9852 - val_loss: 0.0146 - val_r_square: 0.9856\n",
            "Epoch 446/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0146 - r_square: 0.9854 - val_loss: 0.0144 - val_r_square: 0.9858\n",
            "Epoch 447/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0144 - r_square: 0.9856 - val_loss: 0.0142 - val_r_square: 0.9859\n",
            "Epoch 448/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0142 - r_square: 0.9858 - val_loss: 0.0141 - val_r_square: 0.9861\n",
            "Epoch 449/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0141 - r_square: 0.9859 - val_loss: 0.0139 - val_r_square: 0.9863\n",
            "Epoch 450/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0139 - r_square: 0.9860 - val_loss: 0.0137 - val_r_square: 0.9864\n",
            "Epoch 451/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0138 - r_square: 0.9862 - val_loss: 0.0136 - val_r_square: 0.9866\n",
            "Epoch 452/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0137 - r_square: 0.9863 - val_loss: 0.0135 - val_r_square: 0.9867\n",
            "Epoch 453/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0136 - r_square: 0.9864 - val_loss: 0.0134 - val_r_square: 0.9868\n",
            "Epoch 454/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0135 - r_square: 0.9865 - val_loss: 0.0133 - val_r_square: 0.9869\n",
            "Epoch 455/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0133 - r_square: 0.9866 - val_loss: 0.0132 - val_r_square: 0.9870\n",
            "Epoch 456/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0132 - r_square: 0.9867 - val_loss: 0.0130 - val_r_square: 0.9871\n",
            "Epoch 457/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0132 - r_square: 0.9868 - val_loss: 0.0129 - val_r_square: 0.9872\n",
            "Epoch 458/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0131 - r_square: 0.9869 - val_loss: 0.0128 - val_r_square: 0.9873\n",
            "Epoch 459/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0130 - r_square: 0.9870 - val_loss: 0.0128 - val_r_square: 0.9874\n",
            "Epoch 460/2000\n",
            "1530/1530 [==============================] - 0s 19us/step - loss: 0.0129 - r_square: 0.9871 - val_loss: 0.0127 - val_r_square: 0.9875\n",
            "Epoch 461/2000\n",
            "1530/1530 [==============================] - 0s 20us/step - loss: 0.0128 - r_square: 0.9871 - val_loss: 0.0126 - val_r_square: 0.9876\n",
            "Epoch 462/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0127 - r_square: 0.9872 - val_loss: 0.0125 - val_r_square: 0.9876\n",
            "Epoch 463/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0127 - r_square: 0.9873 - val_loss: 0.0124 - val_r_square: 0.9877\n",
            "Epoch 464/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0126 - r_square: 0.9874 - val_loss: 0.0124 - val_r_square: 0.9878\n",
            "Epoch 465/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0125 - r_square: 0.9874 - val_loss: 0.0123 - val_r_square: 0.9879\n",
            "Epoch 466/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0125 - r_square: 0.9875 - val_loss: 0.0122 - val_r_square: 0.9879\n",
            "Epoch 467/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0124 - r_square: 0.9876 - val_loss: 0.0122 - val_r_square: 0.9880\n",
            "Epoch 468/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0123 - r_square: 0.9876 - val_loss: 0.0121 - val_r_square: 0.9881\n",
            "Epoch 469/2000\n",
            "1530/1530 [==============================] - 0s 42us/step - loss: 0.0123 - r_square: 0.9877 - val_loss: 0.0120 - val_r_square: 0.9881\n",
            "Epoch 470/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0122 - r_square: 0.9878 - val_loss: 0.0120 - val_r_square: 0.9882\n",
            "Epoch 471/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0122 - r_square: 0.9878 - val_loss: 0.0119 - val_r_square: 0.9882\n",
            "Epoch 472/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0121 - r_square: 0.9879 - val_loss: 0.0118 - val_r_square: 0.9883\n",
            "Epoch 473/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0120 - r_square: 0.9879 - val_loss: 0.0118 - val_r_square: 0.9884\n",
            "Epoch 474/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0120 - r_square: 0.9880 - val_loss: 0.0117 - val_r_square: 0.9884\n",
            "Epoch 475/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0119 - r_square: 0.9881 - val_loss: 0.0117 - val_r_square: 0.9885\n",
            "Epoch 476/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0119 - r_square: 0.9881 - val_loss: 0.0116 - val_r_square: 0.9885\n",
            "Epoch 477/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0118 - r_square: 0.9881 - val_loss: 0.0115 - val_r_square: 0.9886\n",
            "Epoch 478/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0118 - r_square: 0.9882 - val_loss: 0.0115 - val_r_square: 0.9887\n",
            "Epoch 479/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0117 - r_square: 0.9883 - val_loss: 0.0115 - val_r_square: 0.9887\n",
            "Epoch 480/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0117 - r_square: 0.9883 - val_loss: 0.0114 - val_r_square: 0.9888\n",
            "Epoch 481/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0116 - r_square: 0.9884 - val_loss: 0.0113 - val_r_square: 0.9888\n",
            "Epoch 482/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0116 - r_square: 0.9884 - val_loss: 0.0113 - val_r_square: 0.9889\n",
            "Epoch 483/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0115 - r_square: 0.9885 - val_loss: 0.0112 - val_r_square: 0.9889\n",
            "Epoch 484/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0115 - r_square: 0.9885 - val_loss: 0.0112 - val_r_square: 0.9890\n",
            "Epoch 485/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0115 - r_square: 0.9885 - val_loss: 0.0111 - val_r_square: 0.9890\n",
            "Epoch 486/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0114 - r_square: 0.9886 - val_loss: 0.0110 - val_r_square: 0.9891\n",
            "Epoch 487/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0113 - r_square: 0.9886 - val_loss: 0.0110 - val_r_square: 0.9891\n",
            "Epoch 488/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0113 - r_square: 0.9887 - val_loss: 0.0110 - val_r_square: 0.9892\n",
            "Epoch 489/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0112 - r_square: 0.9887 - val_loss: 0.0109 - val_r_square: 0.9892\n",
            "Epoch 490/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0112 - r_square: 0.9887 - val_loss: 0.0108 - val_r_square: 0.9893\n",
            "Epoch 491/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0112 - r_square: 0.9888 - val_loss: 0.0108 - val_r_square: 0.9893\n",
            "Epoch 492/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0111 - r_square: 0.9889 - val_loss: 0.0108 - val_r_square: 0.9894\n",
            "Epoch 493/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0111 - r_square: 0.9889 - val_loss: 0.0107 - val_r_square: 0.9894\n",
            "Epoch 494/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0110 - r_square: 0.9890 - val_loss: 0.0107 - val_r_square: 0.9894\n",
            "Epoch 495/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0110 - r_square: 0.9890 - val_loss: 0.0106 - val_r_square: 0.9895\n",
            "Epoch 496/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0109 - r_square: 0.9890 - val_loss: 0.0106 - val_r_square: 0.9896\n",
            "Epoch 497/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0109 - r_square: 0.9891 - val_loss: 0.0105 - val_r_square: 0.9896\n",
            "Epoch 498/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0109 - r_square: 0.9891 - val_loss: 0.0105 - val_r_square: 0.9896\n",
            "Epoch 499/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0108 - r_square: 0.9891 - val_loss: 0.0104 - val_r_square: 0.9897\n",
            "Epoch 500/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0108 - r_square: 0.9892 - val_loss: 0.0104 - val_r_square: 0.9897\n",
            "Epoch 501/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0108 - r_square: 0.9892 - val_loss: 0.0104 - val_r_square: 0.9898\n",
            "Epoch 502/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0107 - r_square: 0.9893 - val_loss: 0.0103 - val_r_square: 0.9898\n",
            "Epoch 503/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0107 - r_square: 0.9893 - val_loss: 0.0103 - val_r_square: 0.9899\n",
            "Epoch 504/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0106 - r_square: 0.9894 - val_loss: 0.0102 - val_r_square: 0.9899\n",
            "Epoch 505/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0106 - r_square: 0.9894 - val_loss: 0.0102 - val_r_square: 0.9899\n",
            "Epoch 506/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0105 - r_square: 0.9894 - val_loss: 0.0102 - val_r_square: 0.9900\n",
            "Epoch 507/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0105 - r_square: 0.9895 - val_loss: 0.0101 - val_r_square: 0.9900\n",
            "Epoch 508/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0105 - r_square: 0.9895 - val_loss: 0.0100 - val_r_square: 0.9901\n",
            "Epoch 509/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0105 - r_square: 0.9895 - val_loss: 0.0101 - val_r_square: 0.9900\n",
            "Epoch 510/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0104 - r_square: 0.9896 - val_loss: 0.0100 - val_r_square: 0.9901\n",
            "Epoch 511/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0104 - r_square: 0.9896 - val_loss: 0.0100 - val_r_square: 0.9902\n",
            "Epoch 512/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0104 - r_square: 0.9896 - val_loss: 0.0100 - val_r_square: 0.9901\n",
            "Epoch 513/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0103 - r_square: 0.9897 - val_loss: 0.0099 - val_r_square: 0.9902\n",
            "Epoch 514/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0103 - r_square: 0.9897 - val_loss: 0.0098 - val_r_square: 0.9903\n",
            "Epoch 515/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0103 - r_square: 0.9897 - val_loss: 0.0098 - val_r_square: 0.9903\n",
            "Epoch 516/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0102 - r_square: 0.9898 - val_loss: 0.0098 - val_r_square: 0.9903\n",
            "Epoch 517/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0102 - r_square: 0.9898 - val_loss: 0.0098 - val_r_square: 0.9903\n",
            "Epoch 518/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0102 - r_square: 0.9898 - val_loss: 0.0097 - val_r_square: 0.9904\n",
            "Epoch 519/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0101 - r_square: 0.9899 - val_loss: 0.0097 - val_r_square: 0.9904\n",
            "Epoch 520/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0101 - r_square: 0.9899 - val_loss: 0.0097 - val_r_square: 0.9904\n",
            "Epoch 521/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0101 - r_square: 0.9899 - val_loss: 0.0096 - val_r_square: 0.9905\n",
            "Epoch 522/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0100 - r_square: 0.9899 - val_loss: 0.0096 - val_r_square: 0.9905\n",
            "Epoch 523/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0100 - r_square: 0.9900 - val_loss: 0.0096 - val_r_square: 0.9905\n",
            "Epoch 524/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0100 - r_square: 0.9900 - val_loss: 0.0095 - val_r_square: 0.9906\n",
            "Epoch 525/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0100 - r_square: 0.9900 - val_loss: 0.0095 - val_r_square: 0.9906\n",
            "Epoch 526/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0099 - r_square: 0.9900 - val_loss: 0.0095 - val_r_square: 0.9906\n",
            "Epoch 527/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0099 - r_square: 0.9901 - val_loss: 0.0095 - val_r_square: 0.9907\n",
            "Epoch 528/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0099 - r_square: 0.9901 - val_loss: 0.0095 - val_r_square: 0.9907\n",
            "Epoch 529/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0099 - r_square: 0.9901 - val_loss: 0.0095 - val_r_square: 0.9907\n",
            "Epoch 530/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0098 - r_square: 0.9902 - val_loss: 0.0094 - val_r_square: 0.9907\n",
            "Epoch 531/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0098 - r_square: 0.9902 - val_loss: 0.0094 - val_r_square: 0.9907\n",
            "Epoch 532/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0098 - r_square: 0.9902 - val_loss: 0.0094 - val_r_square: 0.9907\n",
            "Epoch 533/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0098 - r_square: 0.9902 - val_loss: 0.0093 - val_r_square: 0.9908\n",
            "Epoch 534/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0098 - r_square: 0.9902 - val_loss: 0.0093 - val_r_square: 0.9908\n",
            "Epoch 535/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0097 - r_square: 0.9903 - val_loss: 0.0093 - val_r_square: 0.9908\n",
            "Epoch 536/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0097 - r_square: 0.9903 - val_loss: 0.0093 - val_r_square: 0.9908\n",
            "Epoch 537/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0097 - r_square: 0.9903 - val_loss: 0.0093 - val_r_square: 0.9908\n",
            "Epoch 538/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0097 - r_square: 0.9903 - val_loss: 0.0092 - val_r_square: 0.9909\n",
            "Epoch 539/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0097 - r_square: 0.9903 - val_loss: 0.0093 - val_r_square: 0.9908\n",
            "Epoch 540/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0097 - r_square: 0.9903 - val_loss: 0.0092 - val_r_square: 0.9909\n",
            "Epoch 541/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0096 - r_square: 0.9904 - val_loss: 0.0092 - val_r_square: 0.9909\n",
            "Epoch 542/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0096 - r_square: 0.9904 - val_loss: 0.0092 - val_r_square: 0.9909\n",
            "Epoch 543/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0096 - r_square: 0.9904 - val_loss: 0.0092 - val_r_square: 0.9909\n",
            "Epoch 544/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0096 - r_square: 0.9904 - val_loss: 0.0092 - val_r_square: 0.9910\n",
            "Epoch 545/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0096 - r_square: 0.9904 - val_loss: 0.0092 - val_r_square: 0.9909\n",
            "Epoch 546/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0096 - r_square: 0.9904 - val_loss: 0.0091 - val_r_square: 0.9910\n",
            "Epoch 547/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0095 - r_square: 0.9904 - val_loss: 0.0091 - val_r_square: 0.9910\n",
            "Epoch 548/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0095 - r_square: 0.9905 - val_loss: 0.0091 - val_r_square: 0.9910\n",
            "Epoch 549/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0095 - r_square: 0.9905 - val_loss: 0.0091 - val_r_square: 0.9910\n",
            "Epoch 550/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0095 - r_square: 0.9905 - val_loss: 0.0091 - val_r_square: 0.9910\n",
            "Epoch 551/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0095 - r_square: 0.9904 - val_loss: 0.0091 - val_r_square: 0.9910\n",
            "Epoch 552/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0095 - r_square: 0.9905 - val_loss: 0.0090 - val_r_square: 0.9911\n",
            "Epoch 553/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0095 - r_square: 0.9905 - val_loss: 0.0090 - val_r_square: 0.9911\n",
            "Epoch 554/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0095 - r_square: 0.9905 - val_loss: 0.0090 - val_r_square: 0.9911\n",
            "Epoch 555/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0094 - r_square: 0.9905 - val_loss: 0.0090 - val_r_square: 0.9911\n",
            "Epoch 556/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0094 - r_square: 0.9905 - val_loss: 0.0090 - val_r_square: 0.9911\n",
            "Epoch 557/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0094 - r_square: 0.9906 - val_loss: 0.0090 - val_r_square: 0.9911\n",
            "Epoch 558/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0094 - r_square: 0.9906 - val_loss: 0.0090 - val_r_square: 0.9911\n",
            "Epoch 559/2000\n",
            "1530/1530 [==============================] - 0s 20us/step - loss: 0.0094 - r_square: 0.9906 - val_loss: 0.0090 - val_r_square: 0.9911\n",
            "Epoch 560/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0094 - r_square: 0.9906 - val_loss: 0.0090 - val_r_square: 0.9911\n",
            "Epoch 561/2000\n",
            "1530/1530 [==============================] - 0s 20us/step - loss: 0.0094 - r_square: 0.9906 - val_loss: 0.0090 - val_r_square: 0.9912\n",
            "Epoch 562/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0094 - r_square: 0.9906 - val_loss: 0.0090 - val_r_square: 0.9911\n",
            "Epoch 563/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0094 - r_square: 0.9906 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 564/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0094 - r_square: 0.9906 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 565/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0094 - r_square: 0.9906 - val_loss: 0.0090 - val_r_square: 0.9912\n",
            "Epoch 566/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0093 - r_square: 0.9906 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 567/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0093 - r_square: 0.9906 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 568/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 569/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 570/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 571/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0093 - r_square: 0.9906 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 572/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 573/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 574/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 575/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 576/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 577/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 578/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 579/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 580/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 581/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 582/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 583/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 584/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0092 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 585/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0092 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 586/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0092 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 587/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0092 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 588/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0092 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 589/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 590/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0093 - r_square: 0.9907 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 591/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0092 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 592/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 593/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 594/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0092 - r_square: 0.9907 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 595/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 596/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 597/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 598/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 599/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 600/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 601/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 602/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 603/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 604/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 605/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 606/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9914\n",
            "Epoch 607/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 608/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 609/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 610/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 611/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9914\n",
            "Epoch 612/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 613/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 614/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 615/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 616/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9914\n",
            "Epoch 617/2000\n",
            "1530/1530 [==============================] - 0s 44us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 618/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 619/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 620/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 621/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 622/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 623/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 624/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 625/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 626/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9914\n",
            "Epoch 627/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 628/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 629/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 630/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 631/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 632/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 633/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 634/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 635/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 636/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 637/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 638/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 639/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 640/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 641/2000\n",
            "1530/1530 [==============================] - 0s 45us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 642/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 643/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 644/2000\n",
            "1530/1530 [==============================] - 0s 42us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 645/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 646/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 647/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 648/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 649/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 650/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0092 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 651/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 652/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 653/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 654/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 655/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 656/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 657/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 658/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 659/2000\n",
            "1530/1530 [==============================] - 0s 47us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 660/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 661/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 662/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 663/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 664/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 665/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 666/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 667/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 668/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 669/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 670/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0092 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9915\n",
            "Epoch 671/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 672/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 673/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 674/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 675/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 676/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 677/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 678/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 679/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 680/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 681/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9915\n",
            "Epoch 682/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 683/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 684/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 685/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 686/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 687/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 688/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 689/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 690/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 691/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 692/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 693/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 694/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 695/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 696/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 697/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0091 - r_square: 0.9908 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 698/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 699/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 700/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 701/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 702/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 703/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 704/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 705/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 706/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 707/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 708/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 709/2000\n",
            "1530/1530 [==============================] - 0s 42us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 710/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 711/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 712/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 713/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 714/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 715/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 716/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 717/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 718/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 719/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9915\n",
            "Epoch 720/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 721/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 722/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 723/2000\n",
            "1530/1530 [==============================] - 0s 43us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 724/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 725/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 726/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 727/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 728/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 729/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 730/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 731/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 732/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 733/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 734/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 735/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 736/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 737/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 738/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 739/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 740/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 741/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 742/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 743/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 744/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 745/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 746/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 747/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 748/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 749/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 750/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 751/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 752/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 753/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 754/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 755/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 756/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 757/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 758/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 759/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 760/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 761/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 762/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 763/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 764/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 765/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 766/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 767/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 768/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 769/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 770/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 771/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 772/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 773/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 774/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 775/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 776/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 777/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 778/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 779/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 780/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 781/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 782/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 783/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 784/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 785/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 786/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 787/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 788/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 789/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 790/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 791/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 792/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 793/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 794/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 795/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 796/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 797/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 798/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 799/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 800/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 801/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 802/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 803/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 804/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 805/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 806/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 807/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 808/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 809/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 810/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 811/2000\n",
            "1530/1530 [==============================] - 0s 44us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 812/2000\n",
            "1530/1530 [==============================] - 0s 42us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 813/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 814/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 815/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 816/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 817/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 818/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 819/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 820/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 821/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 822/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 823/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 824/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 825/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 826/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 827/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 828/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 829/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 830/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 831/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 832/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 833/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 834/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 835/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 836/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 837/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 838/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 839/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 840/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 841/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 842/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 843/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 844/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 845/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 846/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 847/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 848/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 849/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 850/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 851/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 852/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 853/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 854/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 855/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 856/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 857/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 858/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 859/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 860/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 861/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 862/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 863/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 864/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 865/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 866/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 867/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 868/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 869/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 870/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 871/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 872/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 873/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 874/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 875/2000\n",
            "1530/1530 [==============================] - 0s 43us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 876/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 877/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 878/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 879/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 880/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 881/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 882/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 883/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 884/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 885/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 886/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 887/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 888/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 889/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 890/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 891/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 892/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 893/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 894/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 895/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 896/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 897/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 898/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 899/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 900/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 901/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 902/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 903/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 904/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 905/2000\n",
            "1530/1530 [==============================] - 0s 20us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 906/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 907/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 908/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 909/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 910/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 911/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 912/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 913/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 914/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 915/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 916/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 917/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 918/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 919/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 920/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 921/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 922/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 923/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 924/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 925/2000\n",
            "1530/1530 [==============================] - 0s 18us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 926/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 927/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 928/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 929/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 930/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 931/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 932/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 933/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 934/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 935/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 936/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 937/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 938/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 939/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 940/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 941/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 942/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 943/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 944/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 945/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 946/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 947/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 948/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 949/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 950/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 951/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 952/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 953/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 954/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 955/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 956/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 957/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 958/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 959/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 960/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 961/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 962/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 963/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 964/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 965/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 966/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 967/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 968/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 969/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 970/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 971/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 972/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 973/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 974/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 975/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 976/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 977/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 978/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 979/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 980/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 981/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 982/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 983/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 984/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 985/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 986/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 987/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 988/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 989/2000\n",
            "1530/1530 [==============================] - 0s 20us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 990/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 991/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 992/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 993/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 994/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 995/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 996/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 997/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 998/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 999/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1000/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1001/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1002/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1003/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1004/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1005/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1006/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1007/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1008/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1009/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1010/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1011/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1012/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1013/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1014/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1015/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1016/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1017/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1018/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1019/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1020/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1021/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1022/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1023/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1024/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1025/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1026/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1027/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1028/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1029/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1030/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1031/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1032/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1033/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1034/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1035/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1036/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1037/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1038/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1039/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1040/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1041/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1042/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1043/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1044/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1045/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1046/2000\n",
            "1530/1530 [==============================] - 0s 42us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1047/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1048/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1049/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1050/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1051/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1052/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1053/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1054/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1055/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1056/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1057/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1058/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1059/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1060/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0089 - val_r_square: 0.9912\n",
            "Epoch 1061/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1062/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1063/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1064/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1065/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1066/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1067/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1068/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1069/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1070/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1071/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1072/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1073/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1074/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1075/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1076/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1077/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1078/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1079/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1080/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1081/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1082/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1083/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1084/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1085/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1086/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1087/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1088/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1089/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1090/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1091/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1092/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1093/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1094/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1095/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1096/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1097/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1098/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1099/2000\n",
            "1530/1530 [==============================] - 0s 42us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1100/2000\n",
            "1530/1530 [==============================] - 0s 46us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1101/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1102/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1103/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1104/2000\n",
            "1530/1530 [==============================] - 0s 46us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1105/2000\n",
            "1530/1530 [==============================] - 0s 43us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1106/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1107/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1108/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1109/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1110/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1111/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1112/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1113/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1114/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1115/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1116/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1117/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1118/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1119/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1120/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1121/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1122/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1123/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9913\n",
            "Epoch 1124/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1125/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1126/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1127/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1128/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1129/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1130/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1131/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1132/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1133/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1134/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1135/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 1136/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1137/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1138/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1139/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1140/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1141/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1142/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1143/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1144/2000\n",
            "1530/1530 [==============================] - 0s 43us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1145/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1146/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1147/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1148/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1149/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1150/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1151/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1152/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1153/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1154/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1155/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1156/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1157/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1158/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1159/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1160/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1161/2000\n",
            "1530/1530 [==============================] - 0s 43us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1162/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1163/2000\n",
            "1530/1530 [==============================] - 0s 53us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 1164/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1165/2000\n",
            "1530/1530 [==============================] - 0s 43us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1166/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 1167/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1168/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 1169/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1170/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1171/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1172/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1173/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1174/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1175/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1176/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1177/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1178/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1179/2000\n",
            "1530/1530 [==============================] - 0s 44us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1180/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 1181/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1182/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1183/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1184/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1185/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1186/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1187/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1188/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1189/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1190/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1191/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1192/2000\n",
            "1530/1530 [==============================] - 0s 45us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1193/2000\n",
            "1530/1530 [==============================] - 0s 46us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1194/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1195/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1196/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1197/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1198/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1199/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1200/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 1201/2000\n",
            "1530/1530 [==============================] - 0s 44us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1202/2000\n",
            "1530/1530 [==============================] - 0s 42us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 1203/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1204/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1205/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1206/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1207/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1208/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1209/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1210/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1211/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1212/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1213/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1214/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1215/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1216/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1217/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1218/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1219/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1220/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1221/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1222/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0091 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1223/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 1224/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1225/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1226/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1227/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1228/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1229/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1230/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1231/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1232/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1233/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1234/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1235/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1236/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1237/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1238/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1239/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1240/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1241/2000\n",
            "1530/1530 [==============================] - 0s 44us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1242/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1243/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1244/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1245/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1246/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1247/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1248/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1249/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1250/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1251/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1252/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1253/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1254/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1255/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1256/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1257/2000\n",
            "1530/1530 [==============================] - 0s 43us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1258/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1259/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1260/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1261/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1262/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1263/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1264/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1265/2000\n",
            "1530/1530 [==============================] - 0s 44us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1266/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1267/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1268/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1269/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1270/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1271/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1272/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1273/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1274/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1275/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1276/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1277/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1278/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1279/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1280/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1281/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1282/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1283/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1284/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1285/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1286/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1287/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1288/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1289/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1290/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1291/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1292/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1293/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1294/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1295/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1296/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1297/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1298/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1299/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1300/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1301/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1302/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1303/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1304/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1305/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1306/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1307/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1308/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1309/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1310/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1311/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1312/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1313/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1314/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1315/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1316/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1317/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1318/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1319/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1320/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1321/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1322/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1323/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9911 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1324/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1325/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1326/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1327/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1328/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1329/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1330/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1331/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1332/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1333/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1334/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1335/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1336/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1337/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 1338/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1339/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1340/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1341/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1342/2000\n",
            "1530/1530 [==============================] - 0s 20us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1343/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1344/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1345/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1346/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1347/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1348/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1349/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1350/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1351/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1352/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1353/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1354/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1355/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1356/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1357/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1358/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1359/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1360/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0088 - val_r_square: 0.9913\n",
            "Epoch 1361/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1362/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1363/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1364/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1365/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1366/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1367/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1368/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1369/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1370/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1371/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1372/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1373/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1374/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1375/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1376/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1377/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1378/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1379/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1380/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1381/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1382/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1383/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1384/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1385/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1386/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1387/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1388/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9909 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1389/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1390/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1391/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1392/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1393/2000\n",
            "1530/1530 [==============================] - 0s 43us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1394/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1395/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1396/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1397/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1398/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1399/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1400/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1401/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1402/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1403/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1404/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1405/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1406/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1407/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1408/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1409/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1410/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1411/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1412/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1413/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1414/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1415/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1416/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1417/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1418/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1419/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1420/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1421/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1422/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1423/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1424/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1425/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1426/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1427/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1428/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1429/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1430/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1431/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1432/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1433/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1434/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1435/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1436/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1437/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1438/2000\n",
            "1530/1530 [==============================] - 0s 19us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1439/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1440/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1441/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1442/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1443/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9914\n",
            "Epoch 1444/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1445/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1446/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1447/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1448/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1449/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1450/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1451/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0090 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1452/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1453/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1454/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1455/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1456/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1457/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1458/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1459/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1460/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1461/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9915\n",
            "Epoch 1462/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1463/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1464/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0085 - val_r_square: 0.9915\n",
            "Epoch 1465/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1466/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1467/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1468/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1469/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9915\n",
            "Epoch 1470/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1471/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9915\n",
            "Epoch 1472/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0087 - val_r_square: 0.9914\n",
            "Epoch 1473/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1474/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1475/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1476/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1477/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1478/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1479/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1480/2000\n",
            "1530/1530 [==============================] - 0s 42us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9915\n",
            "Epoch 1481/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1482/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1483/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1484/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1485/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1486/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1487/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9915\n",
            "Epoch 1488/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1489/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1490/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1491/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1492/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1493/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1494/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1495/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1496/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1497/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1498/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1499/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0089 - r_square: 0.9910 - val_loss: 0.0085 - val_r_square: 0.9915\n",
            "Epoch 1500/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1501/2000\n",
            "1530/1530 [==============================] - 0s 43us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1502/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1503/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1504/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1505/2000\n",
            "1530/1530 [==============================] - 0s 19us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1506/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1507/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1508/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1509/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1510/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1511/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9915\n",
            "Epoch 1512/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1513/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1514/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9915\n",
            "Epoch 1515/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1516/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1517/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1518/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1519/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1520/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1521/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1522/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1523/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1524/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1525/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1526/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1527/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1528/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9915\n",
            "Epoch 1529/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1530/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1531/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1532/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1533/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1534/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1535/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1536/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1537/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1538/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1539/2000\n",
            "1530/1530 [==============================] - 0s 16us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1540/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1541/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1542/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0089 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1543/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1544/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1545/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1546/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1547/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1548/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1549/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1550/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1551/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1552/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1553/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1554/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1555/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1556/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1557/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1558/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1559/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0087 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1560/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1561/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1562/2000\n",
            "1530/1530 [==============================] - 0s 41us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1563/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1564/2000\n",
            "1530/1530 [==============================] - 0s 20us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1565/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0088 - r_square: 0.9911 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1566/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1567/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1568/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1569/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1570/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1571/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1572/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1573/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1574/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1575/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1576/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1577/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1578/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1579/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1580/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1581/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1582/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0087 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1583/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1584/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1585/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1586/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1587/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1588/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1589/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1590/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1591/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1592/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0087 - r_square: 0.9912 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1593/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1594/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0087 - r_square: 0.9912 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1595/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0087 - r_square: 0.9912 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1596/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0087 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1597/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0087 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1598/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1599/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1600/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1601/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1602/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1603/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1604/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1605/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1606/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1607/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1608/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1609/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1610/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1611/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1612/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1613/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1614/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1615/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1616/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1617/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1618/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9912 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1619/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1620/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0088 - r_square: 0.9912 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1621/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1622/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1623/2000\n",
            "1530/1530 [==============================] - 0s 39us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1624/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1625/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1626/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1627/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1628/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1629/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1630/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1631/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1632/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1633/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1634/2000\n",
            "1530/1530 [==============================] - 0s 20us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1635/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1636/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1637/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1638/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1639/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1640/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1641/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1642/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1643/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1644/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1645/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1646/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1647/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1648/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1649/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1650/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1651/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1652/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1653/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1654/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1655/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1656/2000\n",
            "1530/1530 [==============================] - 0s 40us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1657/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1658/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1659/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9915\n",
            "Epoch 1660/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1661/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1662/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1663/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1664/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1665/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1666/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1667/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1668/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1669/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1670/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1671/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1672/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1673/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1674/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9915\n",
            "Epoch 1675/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1676/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1677/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1678/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1679/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1680/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1681/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1682/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1683/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1684/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1685/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1686/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1687/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1688/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1689/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1690/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1691/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1692/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1693/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1694/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1695/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1696/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1697/2000\n",
            "1530/1530 [==============================] - 0s 42us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0086 - val_r_square: 0.9915\n",
            "Epoch 1698/2000\n",
            "1530/1530 [==============================] - 0s 43us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1699/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1700/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1701/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1702/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1703/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1704/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1705/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1706/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1707/2000\n",
            "1530/1530 [==============================] - 0s 22us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1708/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1709/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1710/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1711/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1712/2000\n",
            "1530/1530 [==============================] - 0s 21us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1713/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1714/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1715/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1716/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1717/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1718/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1719/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1720/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1721/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1722/2000\n",
            "1530/1530 [==============================] - 0s 36us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1723/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1724/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1725/2000\n",
            "1530/1530 [==============================] - 0s 46us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1726/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1727/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1728/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1729/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1730/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1731/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1732/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1733/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1734/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1735/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1736/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1737/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1738/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1739/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1740/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1741/2000\n",
            "1530/1530 [==============================] - 0s 26us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1742/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1743/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1744/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1745/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1746/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1747/2000\n",
            "1530/1530 [==============================] - 0s 37us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1748/2000\n",
            "1530/1530 [==============================] - 0s 30us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1749/2000\n",
            "1530/1530 [==============================] - 0s 33us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1750/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1751/2000\n",
            "1530/1530 [==============================] - 0s 32us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1752/2000\n",
            "1530/1530 [==============================] - 0s 29us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1753/2000\n",
            "1530/1530 [==============================] - 0s 34us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1754/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1755/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1756/2000\n",
            "1530/1530 [==============================] - 0s 23us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1757/2000\n",
            "1530/1530 [==============================] - 0s 25us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1758/2000\n",
            "1530/1530 [==============================] - 0s 28us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1759/2000\n",
            "1530/1530 [==============================] - 0s 35us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9916\n",
            "Epoch 1760/2000\n",
            "1530/1530 [==============================] - 0s 38us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1761/2000\n",
            "1530/1530 [==============================] - 0s 27us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0084 - val_r_square: 0.9917\n",
            "Epoch 1762/2000\n",
            "1530/1530 [==============================] - 0s 24us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1763/2000\n",
            "1530/1530 [==============================] - 0s 31us/step - loss: 0.0087 - r_square: 0.9913 - val_loss: 0.0085 - val_r_square: 0.9916\n",
            "Epoch 1764/2000\n",
            "1280/1530 [========================>.....] - ETA: 0s - loss: 0.0087 - r_square: 0.9914"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-e7907c5f4a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'history1 = model1.fit(X_Train, y_Train,\\n                  epochs=2000,\\n                  batch_size=256,\\n                  verbose=1,\\n                  validation_data=(X_val, y_val))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YCoAwf5J_Ph",
        "colab_type": "code",
        "outputId": "e395bd57-6ae3-44c5-b523-7ca38a9721d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        }
      },
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "ax = plt.gca()\n",
        "ax.plot(history1.history['loss'],label='Training Data',c='blue')\n",
        "ax.plot(history1.history['val_loss'],label='Validation Data',c='red')\n",
        "plt.ylabel('RMS')\n",
        "plt.legend(loc='center right')\n",
        "\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(history1.history['r_square'],'--',c='blue')\n",
        "ax2.plot(history1.history['val_r_square'],'--',c='red')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "#plt.savefig(\"drive/My Drive/Figures/R2plots/HHag_training\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6UAAAJCCAYAAAA4F2HIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RnX-gI_ZHPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_df=pd.DataFrame()\n",
        "ypred = model2.predict(X_test)\n",
        "\n",
        "extra_results_df = pd.DataFrame([r2_score(y_test[:,i],ypred[:,i]) for i in range(3)],index=['first_ap_time','first_ap_amp','first_ap_width'],columns=['1500 epochs'])\n",
        "results_df = pd.concat([results_df,extra_results_df],axis=1)\n",
        "results_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfbyK8c5LOu1",
        "colab_type": "text"
      },
      "source": [
        "##  Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arKp-9WdLRDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Train, X_test, y_Train, y_test = train_test_split(HHss_ag,HHag,test_size=0.3,random_state=111)\n",
        "scx = StandardScaler()\n",
        "scy = StandardScaler()\n",
        "\n",
        "\n",
        "X_Train = scx.fit_transform(X_Train)\n",
        "y_Train = scy.fit_transform(y_Train)\n",
        "\n",
        "X_test = scx.transform(X_test)\n",
        "y_test = scy.transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjgWQZpbLSeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = models.Sequential()\n",
        "model2.add(layers.Dense(9, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model2.add(layers.Dense(y_train.shape[1]))\n",
        "model2.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z58pH8zjMpmz",
        "colab_type": "code",
        "outputId": "242e1529-b95b-42dc-eec6-1ee0a1c16d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "%%time\n",
        "history2 = model2.fit(X_Train, y_Train,\n",
        "                  epochs=1500,\n",
        "                  batch_size=256,\n",
        "                  verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 36.3 s, sys: 2.44 s, total: 38.7 s\n",
            "Wall time: 41.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0q-YpjWM1pH",
        "colab_type": "code",
        "outputId": "73a81321-f77a-4d57-e94d-603a10ecb92b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "results_df=pd.DataFrame()\n",
        "ypred = model2.predict(X_test)\n",
        "\n",
        "extra_results_df = pd.DataFrame([r2_score(y_test[:,i],ypred[:,i]) for i in range(3)],index=['first_ap_time','first_ap_amp','first_ap_width'],columns=['1500 epochs'])\n",
        "results_df = pd.concat([results_df,extra_results_df],axis=1)\n",
        "results_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1500 epochs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>first_ap_time</th>\n",
              "      <td>0.976530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first_ap_amp</th>\n",
              "      <td>0.999632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first_ap_width</th>\n",
              "      <td>0.997532</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                1500 epochs\n",
              "first_ap_time      0.976530\n",
              "first_ap_amp       0.999632\n",
              "first_ap_width     0.997532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "725E0CvJVPov",
        "colab_type": "text"
      },
      "source": [
        "# Permuted feature importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBp-6x-tle5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = HHag_df.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cxP16y6WvD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from copy import copy\n",
        "\n",
        "def Permuted_feature_impotance(_X,y,model,seeds=[234]):\n",
        "  \n",
        "  base_yhat = model.predict(_X)\n",
        "  base_line = np.array(\n",
        "      [mean_squared_error(y[:,c],base_yhat[:,c])\n",
        "       for c in range(base_yhat.shape[1])])\n",
        "  \n",
        "  PFI = np.zeros((len(seeds),_X.shape[1],y.shape[1]))\n",
        "  \n",
        "  for i,seed in enumerate(seeds):\n",
        "    \n",
        "    np.random.RandomState(seed) # Sets the random state for numpy\n",
        "    for j in range(X_test.shape[1]):\n",
        "      \n",
        "      X = copy(_X)\n",
        "      X[:,j] = np.random.permutation(X[:,j])\n",
        "\n",
        "      perm_yhat = model.predict(X)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "      FI_perm = np.array([mean_squared_error(y[:,c],perm_yhat[:,c]) for c in range(perm_yhat.shape[1])])\n",
        "      PFI[i,j,:] = FI_perm - base_line\n",
        "  \n",
        "  return PFI\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdMDP7bXW6QE",
        "colab_type": "code",
        "outputId": "51a73bdd-1642-440b-ee17-a23ec3fb6dc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "%%time\n",
        "seeds = [123*i for i in range(1,5)]\n",
        "PFI = Permuted_feature_impotance(X_test,y_test,model1,seeds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 773 ms, sys: 84.2 ms, total: 857 ms\n",
            "Wall time: 1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIwNGatRZVVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = np.mean(PFI,axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caucwcMWjqIc",
        "colab_type": "code",
        "outputId": "fd536a66-ebe5-4077-f96a-cb4f9e0f34a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.bar(names,m[:,0])\n",
        "plt.xticks(rotation='vertical');\n",
        "ax = plt.gca()\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(15)\n",
        "    tick.label1.set_fontweight('bold')\n",
        "plt.title(target[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'first_ap_time')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAIdCAYAAAB1HD+dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xu0pFddJ/zvj4SAXMRAWpBcUQOC\nCqg9iCNgEAlRB5MRGMJ4QRcQXwe8zKhjRA03Z4h3lyO+GCSCjoDjJWN8CSAMo8GRjAlORIjGiSGQ\njkYiCYRgSAj83j+ealM56dOnuvv0qdrnfD5r1TpV+9lV59f9rKrzfGvvZz/V3QEAAGA891h2AQAA\nABwcgQ4AAGBQAh0AAMCgBDoAAIBBCXQAAACDEugAAAAGJdABsDRV9YiquryqPl5Vn6mqH192TZuh\nqp5YVVcuuw4Atr9yHToAlqWqXpvk5u7+94f4OtckeX53v2NTCjvw399JTu7uq5bx+wHYuYzQAbBM\nJyZ5/0adqurILagFAIYj0AGwFFX1ziRPTvJLVXVLVb2hqn5itu2UqtpTVT9cVdcn+bWqOqaq/r+q\n+mhV3VhV76qqe1TVbyQ5IckfzF7nP27we3+7qq6vqo9V1cVV9cVz215XVa+uqrfPpoH+cVWduMHr\nXTy7+xez3//svfXP9bmmqn6oqt5bVZ+oqtdW1YOr6i2z3/OOqjp6rv/jq+pPZ//Wv6iqUw7wvxeA\nHUKgA2Apuvtrk7wryYu6+35Jbl/T5SFJHphpFO+sJD+QZE+SXUkenOTF08v0tyX5UJKnd/f9uvun\nNvjVb0lycpLPTfLnSX5zzfZvSfKKJMckuXwf29f+O540u/uY2e//rXW6PiPJU5M8PMnTZ3W8ePbv\nuUeS702Sqjo2yZuT/MTs3/+DSX63qnZt8O8CYAcS6ABYVZ9J8pLuvq27b03yqSSfl+TE7v5Ud7+r\nD+JE8O4+v7s/3t23JXlpksdU1QPmury5uy+ebf/RJF9VVccf+j8n/6W7/6G7r8sUZP93d/+f7v5k\nkguSfNms37cmuai7L+ruz3T325NcluQbNqEGALYZgQ6AVXXDLOzs9dNJrkryh1V1dVWdfaAvWFVH\nVNW5VfW3VXVzkmtmm46Z63bt3jvdfUuSG5M89ICrv7t/mLt/6z4e3292/8Qkz5pNt/xoVX00yRMy\nhVkAuAsnmQOwqu4y+tbdH8807fIHqupLkryzqi7t7v+xtu9+/Nskpyf5ukxh7gFJbkpSc33+eTSu\nqu6Xadrj3x3kv+FgXJvkN7r7BVv4OwEYlBE6AIZQVf+qqr6wqirJx5J8OtO0zGQa7fr8BV7m/klu\nS/KRJPdJ8p/30ecbquoJVXVUpnPpLunua/fRb96iv38R/zXJ06vqabMRxXvPFlk5bpNeH4BtRKAD\nYBQnJ3lHkluSvDvJL3f3/5xte2WSH5tNUfzB/bzGryf5YJLrklyR5JJ99HlDkpdkmmr5FZnOadvI\nS5O8fvb7/80C/dc1C4+nZ1ow5YZMI3Y/FH+zAdgHFxYHgJmqel2SPd39Y8uuBQAW4ds+AACAQQl0\nAGwrVfUtswt8r729/xBe84nrvOYtm1k7ABwoUy4BAAAGZYQOAABgUAIdAADAoFbywuLHHHNMn3TS\nScsuAwAAYCne8573/GN379qo30oGupNOOimXXXbZsssAAABYiqr64CL9TLkEAAAYlEAHAAAwKIEO\nAABgUAIdAADAoAQ6AACAQQl0AAAAgxLoAAAABiXQAQAADEqgAwAAGJRABwAAMCiBDgAAYFACHQAA\nwKAEOgAAgEEJdAAAAIMS6AAAAAYl0AEAAAxKoAMAABiUQAcAADAogQ4AAGBQRy67AAC2t5POfvOy\nS9gRrjn3G5ddAgBLYIQOAABgUAIdAADAoAQ6AACAQQl0AAAAgxLoAAAABiXQAQAADEqgAwAAGJRA\nBwAAMCiBDgAAYFACHQAAwKAEOgAAgEEJdAAAAIMS6AAAAAYl0AEAAAxKoAMAABiUQAcAADAogQ4A\nAGBQAh0AAMCgBDoAAIBBCXQAAACDEugAAAAGdeRGHarq/CT/KsmHu/tL9rH9h5J8y9zrPTLJru6+\nsaquSfLxJJ9Ockd3796swgEAAHa6RUboXpfktPU2dvdPd/dju/uxSX4kyR93941zXZ482y7MAQAA\nbKINA113X5zkxo36zTwnyRsPqSIAAAAWsmnn0FXVfTKN5P3uXHMn+cOqek9VnbVZvwsAAIAFzqE7\nAE9P8r/WTLd8QndfV1Wfm+TtVfXXsxG/u5kFvrOS5IQTTtjEsgAAALanzVzl8sysmW7Z3dfNfn44\nyQVJHrfek7v7vO7e3d27d+3atYllAQAAbE+bEuiq6gFJvibJ78+13beq7r/3fpJTk7xvM34fAAAA\ni1224I1JTklyTFXtSfKSJPdMku5+9azbv07yh939ibmnPjjJBVW19/e8obvfunmlAwAA7GwbBrru\nfs4CfV6X6fIG821XJ3nMwRYGAADA/m3mOXQAAABsIYEOAABgUAIdAADAoAQ6AACAQQl0AAAAgxLo\nAAAABiXQAQAADEqgAwAAGJRABwAAMCiBDgAAYFACHQAAwKAEOgAAgEEJdAAAAIMS6AAAAAYl0AEA\nAAxKoAMAABiUQAcAADAogQ4AAGBQAh0AAMCgBDoAAIBBCXQAAACDEugAAAAGJdABAAAMSqADAAAY\nlEAHAAAwKIEOAABgUAIdAADAoAQ6AACAQQl0AAAAgxLoAAAABiXQAQAADEqgAwAAGJRABwAAMCiB\nDgAAYFACHQAAwKAEOgAAgEEJdAAAAIMS6AAAAAYl0AEAAAxKoAMAABiUQAcAADAogQ4AAGBQAh0A\nAMCgBDoAAIBBCXQAAACDEugAAAAGtWGgq6rzq+rDVfW+dbafUlUfq6rLZ7dz5radVlVXVtVVVXX2\nZhYOAACw0y0yQve6JKdt0Odd3f3Y2e3lSVJVRyR5VZKvT/KoJM+pqkcdSrEAAADcacNA190XJ7nx\nIF77cUmu6u6ru/v2JG9KcvpBvA4AAAD7sFnn0H1VVf1FVb2lqr541nZskmvn+uyZtQEAALAJjtyE\n1/jzJCd29y1V9Q1J/nuSkw/0RarqrCRnJckJJ5ywCWUBAABsb4c8QtfdN3f3LbP7FyW5Z1Udk+S6\nJMfPdT1u1rbe65zX3bu7e/euXbsOtSwAAIBt75ADXVU9pKpqdv9xs9f8SJJLk5xcVQ+rqqOSnJnk\nwkP9fQAAAEw2nHJZVW9MckqSY6pqT5KXJLlnknT3q5M8M8l3V9UdSW5NcmZ3d5I7qupFSd6W5Igk\n53f3+w/LvwIAAGAH2jDQdfdzNtj+S0l+aZ1tFyW56OBKAwAAYH82a5VLAAAAtphABwAAMCiBDgAA\nYFACHQAAwKAEOgAAgEEJdAAAAIMS6AAAAAYl0AEAAAxKoAMAABiUQAcAADAogQ4AAGBQAh0AAMCg\nBDoAAIBBCXQAAACDEugAAAAGJdABAAAMSqADAAAYlEAHAAAwKIEOAABgUAIdAADAoAQ6AACAQQl0\nAAAAgxLoAAAABiXQAQAADEqgAwAAGJRABwAAMCiBDgAAYFACHQAAwKAEOgAAgEEJdAAAAIMS6AAA\nAAYl0AEAAAxKoAMAABiUQAcAADAogQ4AAGBQAh0AAMCgBDoAAIBBCXQAAACDEugAAAAGJdABAAAM\nSqADAAAYlEAHAAAwKIEOAABgUAIdAADAoAQ6AACAQQl0AAAAgxLoAAAABrVhoKuq86vqw1X1vnW2\nf0tVvbeq/rKq/rSqHjO37ZpZ++VVddlmFg4AALDTLTJC97okp+1n+weSfE13f2mSVyQ5b832J3f3\nY7t798GVCAAAwL4cuVGH7r64qk7az/Y/nXt4SZLjDr0sAAAANrLZ59A9L8lb5h53kj+sqvdU1Vmb\n/LsAAAB2tA1H6BZVVU/OFOieMNf8hO6+rqo+N8nbq+qvu/vidZ5/VpKzkuSEE07YrLIAAAC2rU0Z\noauqRyf51SSnd/dH9rZ393Wznx9OckGSx633Gt19Xnfv7u7du3bt2oyyAAAAtrVDDnRVdUKS30vy\nbd39N3Pt962q+++9n+TUJPtcKRMAAIADt+GUy6p6Y5JTkhxTVXuSvCTJPZOku1+d5JwkD0ryy1WV\nJHfMVrR8cJILZm1HJnlDd7/1MPwbAAAAdqRFVrl8zgbbn5/k+ftovzrJY+7+DAAAADbDZq9yCQAA\nwBYR6AAAAAYl0AEAAAxKoAMAABiUQAcAADAogQ4AAGBQAh0AAMCgBDoAAIBBCXQAAACDEugAAAAG\nJdABAAAMSqADAAAYlEAHAAAwKIEOAABgUAIdAADAoAQ6AACAQQl0AAAAgxLoAAAABiXQAQAADEqg\nAwAAGJRABwAAMCiBDgAAYFACHQAAwKAEOgAAgEEJdAAAAIMS6AAAAAYl0AEAAAxKoAMAABiUQAcA\nADAogQ4AAGBQAh0AAMCgBDoAAIBBCXQAAACDEugAAAAGJdABAAAMSqADAAAYlEAHAAAwKIEOAABg\nUAIdAADAoAQ6AACAQQl0AAAAgxLoAAAABiXQAQAADEqgAwAAGJRABwAAMCiBDgAAYFALBbqqOr+q\nPlxV71tne1XVL1bVVVX13qr68rltz62q/zu7PXezCgcAANjpFh2he12S0/az/euTnDy7nZXk/02S\nqnpgkpck+cokj0vykqo6+mCLBQAA4E4LBbruvjjJjfvpcnqSX+/JJUk+p6o+L8nTkry9u2/s7puS\nvD37D4YAAAAsaLPOoTs2ybVzj/fM2tZrBwAA4BCtzKIoVXVWVV1WVZfdcMMNyy4HAABg5W1WoLsu\nyfFzj4+bta3XfjfdfV537+7u3bt27dqksgAAALavzQp0Fyb59tlql49P8rHu/vskb0tyalUdPVsM\n5dRZGwAAAIfoyEU6VdUbk5yS5Jiq2pNp5cp7Jkl3vzrJRUm+IclVSf4pyXfOtt1YVa9IcunspV7e\n3ftbXAUAAIAFLRTouvs5G2zvJC9cZ9v5Sc4/8NIAAADYn5VZFAUAAIADI9ABAAAMSqADAAAYlEAH\nAAAwKIEOAABgUAIdAADAoAQ6AACAQQl0AAAAgxLoAAAABiXQAQAADEqgAwAAGJRABwAAMCiBDgAA\nYFACHQAAwKAEOgAAgEEJdAAAAIMS6AAAAAYl0AEAAAxKoAMAABiUQAcAADAogQ4AAGBQAh0AAMCg\nBDoAAIBBCXQAAACDEugAAAAGJdABAAAMSqADAAAYlEAHAAAwKIEOAABgUAIdAADAoAQ6AACAQQl0\nAAAAgxLoAAAABiXQAQAADEqgAwAAGJRABwAAMCiBDgAAYFACHQAAwKAEOgAAgEEJdAAAAIMS6AAA\nAAYl0AEAAAxKoAMAABiUQAcAADAogQ4AAGBQAh0AAMCgBDoAAIBBLRToquq0qrqyqq6qqrP3sf3n\nq+ry2e1vquqjc9s+Pbftws0sHgAAYCc7cqMOVXVEklcleWqSPUkuraoLu/uKvX26+9/P9f+eJF82\n9xK3dvdjN69kAAAAksVG6B6X5Kruvrq7b0/ypiSn76f/c5K8cTOKAwAAYH2LBLpjk1w793jPrO1u\nqurEJA9L8s655ntX1WVVdUlVnXHQlQIAAHAXG065PEBnJvmd7v70XNuJ3X1dVX1+kndW1V9299+u\nfWJVnZXkrCQ54YQTNrksAACA7WeREbrrkhw/9/i4Wdu+nJk10y27+7rZz6uT/FHuen7dfL/zunt3\nd+/etWvXAmUBAADsbIsEukuTnFxVD6uqozKFtrutVllVX5Tk6CTvnms7uqruNbt/TJKvTnLF2ucC\nAABw4Dacctndd1TVi5K8LckRSc7v7vdX1cuTXNbde8PdmUne1N099/RHJvmVqvpMpvB47vzqmAAA\nABy8hc6h6+6Lkly0pu2cNY9fuo/n/WmSLz2E+gAAAFjHQhcWBwAAYPUIdAAAAIMS6AAAAAYl0AEA\nAAxKoAMAABiUQAcAADAogQ4AAGBQAh0AAMCgBDoAAIBBCXQAAACDEugAAAAGJdABAAAMSqADAAAY\nlEAHAAAwKIEOAABgUAIdAADAoAQ6AACAQQl0AAAAgxLoAAAABiXQAQAADEqgAwAAGJRABwAAMCiB\nDgAAYFACHQAAwKAEOgAAgEEJdAAAAIMS6AAAAAYl0AEAAAxKoAMAABiUQAcAADAogQ4AAGBQAh0A\nAMCgBDoAAIBBCXQAAACDEugAAAAGJdABAAAMSqADAAAYlEAHAAAwKIEOAABgUAIdAADAoAQ6AACA\nQQl0AAAAgxLoAAAABiXQAQAADEqgAwAAGJRABwAAMKiFAl1VnVZVV1bVVVV19j62f0dV3VBVl89u\nz5/b9tyq+r+z23M3s3gAAICd7MiNOlTVEUleleSpSfYkubSqLuzuK9Z0/a3uftGa5z4wyUuS7E7S\nSd4ze+5Nm1I9AADADrbICN3jklzV3Vd39+1J3pTk9AVf/2lJ3t7dN85C3NuTnHZwpQIAADBvkUB3\nbJJr5x7vmbWt9Yyqem9V/U5VHX+AzwUAAOAAbdaiKH+Q5KTufnSmUbjXH+gLVNVZVXVZVV12ww03\nbFJZAAAA29cige66JMfPPT5u1vbPuvsj3X3b7OGvJvmKRZ879xrndffu7t69a9euRWoHAADY0RYJ\ndJcmObmqHlZVRyU5M8mF8x2q6vPmHn5Tkr+a3X9bklOr6uiqOjrJqbM2AAAADtGGq1x29x1V9aJM\nQeyIJOd39/ur6uVJLuvuC5N8b1V9U5I7ktyY5Dtmz72xql6RKRQmycu7+8bD8O8AAADYcTYMdEnS\n3RcluWhN2zlz938kyY+s89zzk5x/CDUCAACwD5u1KAoAAABbTKADAAAYlEAHAAAwKIEOAABgUAId\nAADAoAQ6AACAQQl0AAAAgxLoAAAABiXQAQAADEqgAwAAGJRABwAAMCiBDgAAYFACHQAAwKAEOgAA\ngEEJdAAAAIMS6AAAAAYl0AEAAAxKoAMAABiUQAcAADAogQ4AAGBQAh0AAMCgBDoAAIBBCXQAAACD\nEugAAAAGJdABAAAMSqADAAAYlEAHAAAwKIEOAABgUAIdAADAoAQ6AACAQQl0AAAAgxLoAAAABiXQ\nAQAADEqgAwAAGJRABwAAMCiBDgAAYFACHQAAwKAEOgAAgEEJdAAAAIMS6AAAAAYl0AEAAAxKoAMA\nABiUQAcAADAogQ4AAGBQAh0AAMCgBDoAAIBBCXQAAACDWijQVdVpVXVlVV1VVWfvY/t/qKorquq9\nVfU/qurEuW2frqrLZ7cLN7N4AACAnezIjTpU1RFJXpXkqUn2JLm0qi7s7ivmuv2fJLu7+5+q6ruT\n/FSSZ8+23drdj93kugEAAHa8RUboHpfkqu6+urtvT/KmJKfPd+ju/9nd/zR7eEmS4za3TAAAANZa\nJNAdm+Taucd7Zm3reV6St8w9vndVXVZVl1TVGes9qarOmvW77IYbbligLAAAgJ1twymXB6KqvjXJ\n7iRfM9d8YndfV1Wfn+SdVfWX3f23a5/b3eclOS9Jdu/e3ZtZFwAAwHa0yAjddUmOn3t83KztLqrq\n65L8aJJv6u7b9rZ393Wzn1cn+aMkX3YI9QIAADCzSKC7NMnJVfWwqjoqyZlJ7rJaZVV9WZJfyRTm\nPjzXfnRV3Wt2/5gkX51kfjEVAAAADtKGUy67+46qelGStyU5Isn53f3+qnp5ksu6+8IkP53kfkl+\nu6qS5EPd/U1JHpnkV6rqM5nC47lrVscEAADgIC10Dl13X5TkojVt58zd/7p1nvenSb70UAoEAABg\n3xa6sDgAAACrR6ADAAAYlEAHAAAwKIEOAABgUAIdAADAoAQ6AACAQQl0AAAAgxLoAAAABiXQAQAA\nDEqgAwAAGJRABwAAMCiBDgAAYFACHQAAwKCOXHYBIznp7Dcvu4Rt75pzv3HZJQAAwDCM0AEAAAxK\noAMAABiUQAcAADAogQ4AAGBQAh0AAMCgBDoAAIBBCXQAAACDEugAAAAGJdABAAAMSqADAAAYlEAH\nAAAwKIEOAABgUAIdAADAoAQ6AACAQQl0AAAAgxLoAAAABiXQAQAADEqgAwAAGJRABwAAMCiBDgAA\nYFACHQAAwKAEOgAAgEEJdAAAAIMS6AAAAAYl0AEAAAxKoAMAABiUQAcAADAogQ4AAGBQRy67AAAA\n4O5OOvvNyy5hR7jm3G9cdgmHxAgdAADAoAQ6AACAQQl0AAAAg1oo0FXVaVV1ZVVdVVVn72P7varq\nt2bb/3dVnTS37Udm7VdW1dM2r3QAAICdbcNFUarqiCSvSvLUJHuSXFpVF3b3FXPdnpfkpu7+wqo6\nM8lPJnl2VT0qyZlJvjjJQ5O8o6oe3t2f3ux/CLB9OSl8a4x+Ujhwdz4/t4bPT5ZpkRG6xyW5qruv\n7u7bk7wpyelr+pye5PWz+7+T5ClVVbP2N3X3bd39gSRXzV4PAACAQ7TIZQuOTXLt3OM9Sb5yvT7d\nfUdVfSzJg2btl6x57rEHXS0AsKWM8GwNIzzAwVqZ69BV1VlJzpo9vKWqrlxmPdvEMUn+cdlFHIj6\nyWVXsFKG23/cxXD7z/vvLuy/sdl/Y7P/xmb/bZ4TF+m0SKC7Lsnxc4+Pm7Xtq8+eqjoyyQOSfGTB\n5yZJuvu8JOctUjSLqarLunv3suvg4Nh/Y7P/xmb/jc3+G5v9Nzb7b+stcg7dpUlOrqqHVdVRmRY5\nuXBNnwuTPHd2/5lJ3tndPWs/c7YK5sOSnJzkzzandAAAgJ1twxG62TlxL0rytiRHJDm/u99fVS9P\ncll3X5jktUl+o6quSnJjptCXWb//luSKJHckeaEVLgEAADbHQufQdfdFSS5a03bO3P1PJnnWOs/9\nT0n+0yHUyMEzhXVs9t/Y7L+x2X9js//GZv+Nzf7bYjXNjAQAAGA0i5xDBwAAwAoS6AAAAAYl0AEA\n21ZVHb3sGgAOJ4EOVlhVPbSqvr2qvn3ZtQCsiqr6jgX7HZvkXYe3GthZquqzD6Dvdx3OWphYFGUb\nqaovTfK8JA9Pcu81m7u7n7L1VXEoquppSd6S5DPdvdCqtKyWqnpSktdleg9+wZLLYR1VdUSSr0xy\nfJJ7rd3e3b++5UWxrqr6dJIf6O5f2E+fk5O8Pcnx3X3ElhXHQZmNpJ6cux+/pLsv3vqKWE9V/XmS\nU7v7Hzfo9+NJXur9d/g5QNwmquqUJG9Ncs99bU4iuY+tll0AB+2zkpwU78GVVVVfnuT3MoW5fekk\nAt1qqSQ/W1UP6u4fv9vGqq/IdLmlXfHeW2lVdZ9M1zN+Vvb9t67jeHXVPDbJn1TVqd39oX11qKpf\nSPK98f7bEqZcbh8vTnJUkltz5wfijbP7H03ywSXVBbDqfjnJCZk+L9e7sVquyLRfXlxVvzy/oaqe\nnOSdSY6ZNZ2/xbVxYF6S5NmZjkm9/8ZxcqZQ90XzjVV1RFX91yTfM2v66JZXtgMJdNvH7kzfgjxp\nb0N370pydpJPJ3nmkuoCWHVfkunz8xeSPC3Jk9fcvnZ5pbGOJyb5s0wH+99VVW+oqiOr6hmZRubu\nP9v2U939giXWyca+OdP77zWzx50pDPx1kquSPH9JdbG+7860n45N8q6q+hdJUlX3TnJhkudkev9d\nn+SUJdW4oziHbpuoqtuTHJFplO62TG+ke80e35Lkku7+l8urkLWq6pwFun1hkm/NdP6VOegDmjsP\n0j5cUVX17iSPS/Kg7vZt8iCq6r5J/nuSp2Q6uPyLJF+a6W9hkvzH7v6ZJZXHgqrqk5lOFzkmyUcy\n+6ysqkck+ask53b3i5dZI3dXVc/ONBX9npmOM5+X5PuTPD7TMejVSZ7a3R9YWpE7iEC3TVTVh5M8\nKMlnJ7kmyQOT/Lskn8j0hru1u++7tAK5m6r6TBabW14RBlbSbGGGhbrGPlxZVfXYTItnXJLkZ5N8\nKMkd833WO0+E5aqqo5K8IXeO8lSmfXdWd79uiaWxoKr6eJL75M4voI/KdD7rrZkC3g3d/eDlVch6\nquq0JL+Taf/tPZ6pJO9N8rTu/odl1bbTCHTbRFVdkuRfJHlkkv+S5Km5a1j46+7+4mXUxr7NAt2i\nhIEVZB9uD1W1K9OiKOvNYmirzK6WNTMcjkzyoiSfk+nv3iVJ3jbfv7tfvnXVcSCq6uokJyZ5SJKL\nM63U/b4kn0ry5Ulu6u4HLa9C9qeqvirJm3Pn++9Pkjy9u29eamE7jD9Q28cFmd5IX5DkZZmGvO8/\n2/apTIumsFq+c9kFcMg+FCt4bQfnZwpzFl8Yx0tz9/fe3sePn93mCXSr6/JMKwE/JtOxzNmZzmvd\n66Il1MR+rDM7Ze/77wlJbqr6549TX4htASN021RVnZjp5P6jkvxhd//Nkktik8yua+a6PLBJquoT\nma599b9mt0+u7dPdL9vqulif0fHto6oenuRhmc6Xuz7Jz2RayO2oTCM/3+fc1tWyj/fffJhY+8WY\n998WEOhgMLMPUhcaH1hVvTPTH7mnLLsWkqq6IskjknxOd3982fWwsap67oH07+7XH65aYKepqmty\nALNTuvthh68aEoFuaFV1QNMou/s/H65a2Dp7F1Pxjde47MPVUlWnJvn9JK9M8pPdfduSS+IwMcMB\n2I4EuoEdwCqJSRIHj9uDMDA++3C1zBZlOCbJfZPcnuSG3HWVy+7uL1hGbWwuMxxWw+xSS4vq7r7X\nYSuGLWN2yuEj0A3MOQQ7kzAwPvtwtcx9Obbeoij21TbhvbcaHL/sTN5/h49vqMb25HXaj0ryHUn+\nTZJ7ZDpIuWGLagIYzcWxWilspf29547MtErp3uMXYAMC3cC6+4/nH1fVZyX5riQ/kOShmT4I92Ra\nMeo1W14gwIqqaU3t+ydJd5+yTp/Pnt29ZYvKgh1hX++5qrpXkucn+cHcGeauT/JzW1ocDOgeyy6A\nQ1dVD6iqH0vywSQ/m+TYJFdl+mD8/O7+xe6+dZk1AqyYs5LclGlZ9PW8ddbn+VtSEexAVXW/qvqP\nST6Q5BczXWT8miT/LslJ3f0zSywPhmCEbmBV9blJ/kOS/yfTN82V5C8yrdT22+0EySFU1b2TvCHT\n9JMf7u6rNnjKelNtWVFVdUIofyDZAAAKn0lEQVSSdPeHZk2m+C3fs2c/z91Pn1dmWv3yzCTnHfaK\nYAepqgcm+f4kL0zyOZmOYa7I9J58Y3fv6+LVwD5YFGVgVfVPSe6V6UPwjiS/nf1829zdb9ii0jhA\nVXVzphX27mc0dRz7WjGvqn4v00nfz9hfP5arqv4uyYOzn2vPVdX9k3wsyfXd/dCtrI/Dw6IMq6Gq\nfi7JC5LcJ9MxzJ8leWV3//5SC+Ow8v47fAS6gR3gZQvaweTqqqr/luQZSb66uy9Zdj0sZl9/nBZt\nY7mq6pNJ7pnkvt39yXX6fFaSTyS5vbvvvZX1sZgDneFQVV+T3P0cdLbWmpVl78g0xXI93d2P2Iq6\n2FxrZ6dU1R9ND9tMo00m0A3Msr/bR1U9K8mrk3wy0wngfzm7/89cCHf1CHTjqqprMy0e9c3rjQpU\n1elJLkhyXXcfv5X1sTgzHMazny+k51e13Bv4fHauGLNTVo//4LF957ILYNP8Vu784/ZT+9je8X6F\nzfQnmc6je3VV/VN3v31+Y1V9XaYvWXrWl9X11kwzHB6TxAyHMXwoziMe3dpLSpyRjUM6h4kRuh2o\nqp6UGPFZJQuMtvqGcgXNfct8Su78o/VH67XZh6ujqv5lknfNNf11kitn9x+R5IsyGx1I8oTufvfW\nVsiizHCArWV2yuoR6HYgQ+Crp6qeu1Gf7n79VtTC4g7gPFbThlZQVf14kpfNHq7dj3vD+Dnd/RNb\nVxUHaoH3oXPIt4mqemem/fmUZdeykwl0q0eg24G8wWBzOI91fFX1jCQ/nuTRaza9N8nLuvuCra+K\nA2GGw87h+GU1mJ2yegS6HcgH4uqqqqOTnJzkbivqmTK0eqrq1w6kf3c773VFVdVDkpyQ6YDkQ939\nD0suiQWZ4bBzOH5ZDWanrB6Bbgfygbh6quo+SV6b5FnZ9wnEpgwBsKM5flkNZqesHgeIsBpekmnF\nPQAOghkOsGWMeK8YgQ5Wwzdnmr7wq0leMLv/vUlemOl9+srllQawuhaZ4RDHO7BpnD6weu6x7AKA\nJMneixafvbehu1+V5F8n+cJM3zoDcHd7ZzjcI1Og29cNYNsS6LaBqrp3Vf1eVf1uVX3hAk95cpKv\nPdx1cUA+Nft5c5LbkqSqHprkw7P25y2jKIAB7J3h8JrZ407yPZmuLXhVkucvqS4OUVWdUFUnzDVd\nPLsBcyyKsk1U1c1J7pvkft1967Lr4cBU1dVJTkzykEx/rB6e5H2Zgt6XJ7mpux+0vAoBVlNVfTLJ\nPZMck+QjmS3CUFWPSPJXSc7t7hcvs0bual/Xw62q38u0756xv37A3Rmh2z7eOvv5mKVWwcG6PNO0\noMckuWB2/0uSfNls+0VLqgtg1ZnhMKa1U2HPmN026ges4RuP7eO3kzwlye9W1c8l+cskn5zvYJWv\nlXZ2kl9J8jeZRujul+SZSY5K8uYk37e80gBW2g2ZZjg8MMk1mWY4vCV3Bj3HOsC2ZsrlNrHARR5d\nxwyAbWc2Ve+MJKdmOj/87Nz597CS/GZ3f9uSymMf9nU9uUXbgLtzgL+9mJYwsKqqJP82yVcnOTbJ\ndUn+JMkb2zcvAOsxw2FQVfXErDl22VcbsH9G6LaJqnruRn2624UgV1RVHZ9pitAj97H5iiRf3917\ntrYqANh8C8wq+ueuMUIHGxLoYAVU1R8k+cZ1NneSN3f3N21hSQDDMMNhLLNAtyiBDjYg0G0zVXV0\npotQ33vtNouirK6q+kSmffaGJOdkOhg5NskrMh2k3Nrd911ehQCryQyH8VTVrx1I/+7+zsNVC2wH\nAt02UVX3SfLaJM/KvueeWxRlhVXVniSfl+SB3f2xufYHJLkpyXXdffyy6gNYVWY4ADud69BtHy9J\n8uxM+7TWubG6XjX7+eg17Y9esx2Au/raTMHtN5N8QabZDl+QacZDZbqkD8C2ZcRm+/jmTH/QfjXJ\nC2b3vzfJCzPt51curzT2parOmX+Y5B+SvLmqLkhybZLjMu3Xv09yr62vEGAIN2Wa4fCiuRkOH6iq\nF2aasn7j0ioD2AKmXG4TVfXJJPdMckySj2R2EnFVPSLJXyU5t7tfvMwauasDWOUrMWUWYJ+q6keS\n/ESSU7r7XXPtT0zyx0le3N3nLqs+gMPNAeL28alMge7mJLclOaqqHprkw7Ptz0si0K0eU2EBDpAZ\nDgB3MkK3TVTV1UlOTPKQTBdWfXiS92UKel+e5KbuftDyKmStqjrxQPp39wcPVy0AIzHDAeBOPuC2\nj8uTnJTkMUkuSHJ2ki+Z237REmpiP+YDWlV9+/66Jrmpqm7p7o8c/soAhmCGA0CM0G0bVfXwJA/L\ndL7c9Ul+JskzkxyV5M1Jvq+7P7q8CtmfBb9tvj3JOd3901tQEsDKMsMB4E4CHayAWaBbRCc5o7v/\n4HDWAzCKRWY4JHm3GQ7AdiXQbSNVVZmWaP7qJMcmuS7JnyR5Y9vRK62qnp7k1ZmW1/75JHuSHJ/k\n+5M8MMmPJfmOJE9M8o7uPnU5lQKsFjMcgJ1OoNsmqur4JG9J8sh9bL4iydd3956trYpFVdVrMwW2\nk7r72rn2E5N8IMnrk/xgpum0N1vgBmBihgOw091j2QWwaX45yaMynSS+9vao2XZW1zNnP++zpv2o\n2c8zZtOFrk9yvy2rCmD1nZ7p8gTvT/L8JKclecHs8d9numzPuzL9PfyeJdUIcNhY5XL7+NpM3z6+\nIck5maZbHpvkFZmmYT5leaWxgNsyBbW3VdVrMu2/z8t0IJJMl59IkvtnmpYJwOSMTJfsefyaGQ7v\nyDTD4UmZrkl3fZKvWEqFAIeRKZfbRFXtyRQAHtjdH5trf0CmE8Kv6+7jl1Uf+1dVr0zyw7n7eSB7\nl+V+ZZJfz7SK6du6++u3sDyAlVVVH8v0hdijuvvKufaTk1yZ5GPdfXRVXZvkc7vbhcaBbcUI3fbx\nqiQ/keTRmaaW7PXoue2srh/NNAr3/bnrlMpbMi2S8rJM1xn8tkzTiACYmOEA7GhG6AZWVefMP0zy\nXZn+qF2Q5Nokx2WaZvLxJOd198u2vEgOyGxE9dGZDkb+Lsl7u/vm5VYFsLrMcAB2OoFuYAsu1bxX\nd7cRWQC2laq6R5KXZuMZDl+V5P3dffkWlwhwWAl0AzuApZqTKdAdcdiKAYAlMsMB2KkEuoHNrlG2\nsO7+4OGqBQAA2Hqm4A1sPqBV1bfvr2uSm6rqltm1zAAAgG3ACN02seD5dLcnOae7f3oLSgIAAA4z\ngW6bOIDz6TrJGd39B4ezHgAA4PC7x7ILYNOcnuTvM12j7PlJTkvygtnjv890PZ53ZVrG+XuWVCMA\nALCJnEO3fZyR5CFJHt/d1+5trKp3JPlAkidluibd9Um+YikVAgAAm8oI3fbxzNnP+6xpP2r284zZ\ngijX567X6QEAAAZlhG77uC1TUHtbVb0myXWZrsXzvNn2T81+3j/JjVtfHgAAsNkEuu3jtUl+OMnx\nSV4+116zn6+pqkck+ewk797i2gAAgMNAoNs+fjTTKNz3565TKm9J8vNJXpbkpCTflmmhFAAAYHAu\nW7DNVNUDkjw603TLv0vy3u6+eblVAQAAh4NABwAAMCirXAIAAAxKoAMAABiUQAcAADAogQ4AAGBQ\nAh0AAMCg/n9QEkWJBa0aVQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKRJFUM5jqM5",
        "colab_type": "code",
        "outputId": "bedd2cad-9693-4aad-92ca-34805cd1ff16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.bar(names,m[:,1])\n",
        "plt.xticks(rotation='vertical');\n",
        "ax = plt.gca()\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(15)\n",
        "    tick.label1.set_fontweight('bold')\n",
        "plt.title(target[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'first_ap_amp')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAIdCAYAAAB1HD+dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3Ke7n9WWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq7Pnq8DkHOC",
        "colab_type": "code",
        "outputId": "41ca3316-48c5-49cd-ba6d-9fcbbf51b81d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.bar(names,m[:,2])\n",
        "plt.xticks(rotation='vertical');\n",
        "ax = plt.gca()\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(15)\n",
        "    tick.label1.set_fontweight('bold')\n",
        "plt.title(target[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'first_ap_width')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAIdCAYAAACup5W/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TmLJReGsYJS",
        "colab_type": "code",
        "outputId": "9079cfa3-300d-44c4-9906-7fef9bd04770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "target"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['first_ap_time', 'first_ap_amp', 'first_ap_width'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0G1KU8jqh6u",
        "colab_type": "code",
        "outputId": "131c8d60-0870-4a6e-ff11-5cace0e4620f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "xa = np.array([i for i in range(len(names))])\n",
        "plt.bar(xa-0.2,m[:,0],width=0.2)\n",
        "plt.bar(xa,m[:,1],width=0.2)\n",
        "plt.bar(xa+0.2,m[:,2],width=0.2)\n",
        "plt.legend(['Time of AP','Amplitude of AP','AP width'])\n",
        "\n",
        "plt.xticks(xa,names,fontsize=15,fontweight='bold')\n",
        "plt.xticks(rotation='vertical');\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(15)\n",
        "    tick.label1.set_fontweight('bold')\n",
        "plt.ylabel('Feature Importance')\n",
        "plt.savefig(\"drive/My Drive/Figures/R2plots/HHperm_ag\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAIQCAYAAADU0NCdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZKkIWMhKEmSJElD5n8di06Om8MAPgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mllc1SwqsgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnYCoxN5qsqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sCwKdnVvX57",
        "colab_type": "code",
        "outputId": "4066f573-31a2-4190-a406-9bf64c03d708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "foonames = [n for _,n in sorted(zip(m[:,0],names))]\n",
        "foom = sorted(m[:,0])\n",
        "foonames.reverse()\n",
        "foom.reverse()\n",
        "plt.bar(foonames,foom)\n",
        "plt.xticks(rotation='vertical');\n",
        "ax = plt.gca()\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(15)\n",
        "    tick.label1.set_fontweight('bold')\n",
        "plt.savefig(\"drive/My Drive/Figures/R2plots/HHperm_firstap\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAIQCAYAAADJgixDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMCiBDgAAYFD/P1T7yRPcgVRtAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWbpauJKvlRw",
        "colab_type": "code",
        "outputId": "5047acd2-c984-4453-f52c-85a7d9c55dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "foonames = [n for _,n in sorted(zip(m[:,1],names))]\n",
        "foom = sorted(m[:,1])\n",
        "foonames.reverse()\n",
        "foom.reverse()\n",
        "plt.bar(foonames,foom)\n",
        "plt.xticks(rotation='vertical');\n",
        "ax = plt.gca()\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(15)\n",
        "    tick.label1.set_fontweight('bold')\n",
        "plt.savefig(\"drive/My Drive/Figures/R2plots/HHperm_firstapamp\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAIQCAYAAADJgixDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOgAAgEH9/2ExWh0C38j1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoKBFWBMvlOK",
        "colab_type": "code",
        "outputId": "cdc42d1b-bbcc-4ebf-ddf8-948df7757427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "foonames = [n for _,n in sorted(zip(m[:,2],names))]\n",
        "foom = sorted(m[:,2])\n",
        "foonames.reverse()\n",
        "foom.reverse()\n",
        "plt.bar(foonames,foom)\n",
        "plt.xticks(rotation='vertical');\n",
        "ax = plt.gca()\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(15)\n",
        "    tick.label1.set_fontweight('bold')\n",
        "plt.savefig(\"drive/My Drive/Figures/R2plots/HHperm_firstapwidth\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAIQCAYAAAASOYZhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}